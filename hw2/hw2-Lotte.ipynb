{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "549d14426afb2109edb71ef6e0223d5b",
     "grade": false,
     "grade_id": "cell-133a4667b3e842fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Homework 2: Learning to Rank <a class=\"anchor\" id=\"toptop\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "188d0bd6218df31e0a8795322a1b9912",
     "grade": false,
     "grade_id": "cell-9409dd22f820096c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Submission instructions**:\n",
    "- Only the code `TODO: Implement this!` denotes that these sections are graded. Please do not delete the comment #YOUR CODE HERE.\n",
    "- Vectoriize your code instead of using for-loop when implementing Neural Nets.\n",
    "- The notebook you submit has to have the student ids, separated by underscores (E.g., `12341234_12341234_12341234.ipynb`). \n",
    "- This will be parsed by a regexp, so please double check your filename.\n",
    "- Only one member of each group has to submit the file to canvas.\n",
    "- Make sure to check that your notebook runs before submission. A quick way to do this is to restart the kernel and run all the cells.  \n",
    "- Please do not delete/add new cells. Removing cells can lead to grade deduction. Also do not change the number of parameters in the pre-defined functions.\n",
    "- Note, that you are not allowed to use Google Colab.\n",
    "\n",
    "**Learning Goals**:\n",
    "- Part 1: Offline LTR\n",
    "  - Learn how to implement pointwise, pairwise and listwise algorithms for learning to rank \n",
    "- Part 2: Online LTR\n",
    "  - Implement learning to rank algorithms from historical clicks and online evaluation of ranking algorithms.\n",
    "- Learn their weaknesses & strengths and when each method is suitable. \n",
    "\n",
    "\n",
    "\n",
    "**Files to submit along with the completed notebook**:\n",
    "- `pointwise_regression.json`\n",
    "- `pointwise_classification.json`\n",
    "- `pairwise.json`\n",
    "- `listwise.json`\n",
    "- `biased_model.json'\n",
    "- `unbiased_model.json'\n",
    "\n",
    "\n",
    "---\n",
    "**Recommended Reading**:\n",
    "- Part 1:\n",
    "  - Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton, and Greg Hullender. Learning to rank using gradient descent. InProceedings of the 22nd international conference on Machine learning, pages 89–96, 2005.\n",
    "  - Christopher J Burges, Robert Ragno, and Quoc V Le. Learning to rank with nonsmooth cost functions. In Advances inneural information processing systems, pages 193–200, 2007\n",
    "  - (Sections 1, 2 and 4) Christopher JC Burges. From ranknet to lambdarank to lambdamart: An overview. Learning, 11(23-581):81, 2010\n",
    "  \n",
    "\n",
    "Additional Resources: \n",
    "- This assignment requires knowledge of [PyTorch](https://pytorch.org/). If you are unfamiliar with PyTorch, you can go over [these series of tutorials](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
    "\n",
    "In the previous assignment, you experimented with retrieval with different ranking functions and in addition, different document representations. \n",
    "\n",
    "This assignment deals directly with learning to rank (LTR). In offline LTR (Part 1), You will learn how to implement methods from the three approaches associated with learning to rank: pointwise, pairwise and listwise. \n",
    "\n",
    "In Part 2, you will learn about online LTR. Instead of using manually judged datasets, in online LTR, we learn from user interactions. You will learn how to simulate clicks using click models, how to learn unbiasedly from historical clicks and how to evaluate different rankers in an online environment using multileaving methods. \n",
    "\n",
    "**Note:**\n",
    "  - The dataset used in this assignment is +100Mb in size. You may need around 2Gb of RAM for running the whole notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a595c150f39970fb6ad72e463fe8b44",
     "grade": false,
     "grade_id": "cell-09127508ac207429",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Table of Contents  <a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "[Back to top](#toptop)\n",
    "\n",
    "\n",
    "Table of contents:\n",
    "\n",
    "\n",
    " - [Chapter 1: Offline LTR](#o_LTR) (345 points)\n",
    "     - [Section 1: Dataset and Utility](#dataU) \n",
    "     - [Section 2: Pointwtise LTR](#pointwiseLTR) (55 points)\n",
    "     - [Section 3: Pairwise LTR](#pairwiseLTR) (60 points)\n",
    "     - [Section 4: Pairwise Speed-up RankNet](#SpairwiseLTR) (70 points)\n",
    "     - [Section 5: Listwise LTR](#listwiseLTR) (80 points)\n",
    "     - [Section 6: Evaluation](#evaluation1) (70 points)\n",
    " - [Chapter 2: Online LTR](#onLTR) (180 points)\n",
    "     - [Section 1: Clicks Simulation](#clicks) (15 points)\n",
    "     - [Section 2: Counterfactual](#cLTR) (90 points)\n",
    "     - [Section 3: Online Evaluation](#on_eval) (75 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7be29958190a403c77402e97c21c5252",
     "grade": false,
     "grade_id": "cell-b08a635cb01047dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import itertools\n",
    "from argparse import Namespace\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import dataset\n",
    "import evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f126271fe03e0c82c752179a1293748",
     "grade": false,
     "grade_id": "cell-ef602d983baa9d90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Chapter 1: Offline LTR <a class=\"anchor\" id=\"o_LTR\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83d5c5098ff7e903a1d4475f78d028be",
     "grade": false,
     "grade_id": "cell-9978e0796016b961",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A typical setup of learning to rank involves a feature vector constructed using a query-document pair, and a set of relevance judgements. You are given a set of triples (`query`, `document`, `relevance grade`); where relevance grade is an *ordinal* variable  with  5  grades,  for example: {`perfect`,`excellent`,`good`,`fair`,`bad`),  typically  labeled  by human annotators.  \n",
    "\n",
    "In this assignment, you are already given the feature vector for a given document and query pair. To access these vectors, see the following code cells (note: the dataset will be automatically downloaded & the first time the next cell runs, it will take a while!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "62aa687b659ad249d6b6190d4b1f7d9e",
     "grade": false,
     "grade_id": "cell-d60b3e2cd8d41210",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Section 1: Data and Utility <a class=\"anchor\" id=\"dataU\"></a>\n",
    "\n",
    "[Back to TOC](#top)\n",
    "\n",
    "First let's get familiar with the dataset and some utility methods for our implementations.\n",
    "\n",
    "### Section 1.1 Dataset stats\n",
    "\n",
    "| Split Name | \\# queries | \\# docs | \\# features |\n",
    "| :- | :--: | :--: | :--: |\n",
    "| train | 2735 | 85227 | 501 |\n",
    "| validation | 403 | 12794 | 501 |\n",
    "| test | 949 | 29881 | 501 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e11c95b755f0b252276313365c6ff290",
     "grade": false,
     "grade_id": "cell-d4779843ecb42649",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dataset.download_dataset()\n",
    "data = dataset.get_dataset()\n",
    "# there is only 1 fold for this dataset \n",
    "data = data.get_data_folds()[0]\n",
    "# read in the data\n",
    "data.read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8008b140d6012489be5056ec30e90444",
     "grade": false,
     "grade_id": "cell-2a79356db5683374",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 501\n",
      "Split: train\n",
      "\tNumber of queries 2735\n",
      "\tNumber of docs 85227\n",
      "Split: validation\n",
      "\tNumber of queries 403\n",
      "\tNumber of docs 12794\n",
      "Split: test\n",
      "\tNumber of queries 949\n",
      "\tNumber of docs 29881\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features: {data.num_features}\")\n",
    "# print some statistics\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    print(f\"Split: {split}\")\n",
    "    split = getattr(data, split)\n",
    "    print(f\"\\tNumber of queries {split.num_queries()}\")\n",
    "    print(f\"\\tNumber of docs {split.num_docs()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "70b764af87765e64827eb896b0ad8643",
     "grade": false,
     "grade_id": "cell-5b034476f52f28bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Section 1.2 Utility classes/methods\n",
    "\n",
    "The following cells contain code that will be useful for the assigment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb52800727e7a5fe81c92706c34e6471",
     "grade": false,
     "grade_id": "cell-4ad2f0d8e4f66d37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# these is a useful class to create torch DataLoaders, and can be used during training\n",
    "class LTRData(Dataset):\n",
    "    def __init__(self, data, split):\n",
    "        split = {\n",
    "            \"train\": data.train,\n",
    "            \"validation\": data.validation,\n",
    "            \"test\": data.test\n",
    "        }.get(split)\n",
    "        assert split is not None, \"Invalid split!\"\n",
    "        features, labels = split.feature_matrix, split.label_vector\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.labels = torch.FloatTensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.features.size(0)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.features[i], self.labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61170cd9d5a02b3f9e23364bf7d46c95",
     "grade": false,
     "grade_id": "cell-6be5d30fd0264dc3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 501]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "## example \n",
    "train_dl = DataLoader(LTRData(data, \"train\"), batch_size=32, shuffle=True)\n",
    "# this is how you would use it to quickly iterate over the train/val/test sets \n",
    "# - (of course, without the break statement!)\n",
    "for (x, y) in train_dl:\n",
    "    print(x.size(), y.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50bdb8c74b13357983e5f5f435b70115",
     "grade": false,
     "grade_id": "cell-a79c0f58db4af010",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "`evaluate_model` evaluates a model, on a given split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ca1e81dd1f55111cda0a04093fd223b",
     "grade": false,
     "grade_id": "cell-b66759e20b89e0b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this function evaluates a model, on a given split\n",
    "def evaluate_model(pred_fn, split, batch_size=256, print_results=False, q_level=False):\n",
    "    dl = DataLoader(LTRData(data, split), batch_size=batch_size)\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "    for (x, y) in tqdm(dl, desc=f'Eval ({split})', leave=False):\n",
    "        all_labels.append(y.squeeze().numpy())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = pred_fn(x)\n",
    "            all_scores.append(output.squeeze().numpy())\n",
    "            \n",
    "    split = {\n",
    "            \"train\": data.train,\n",
    "            \"validation\": data.validation,\n",
    "            \"test\": data.test\n",
    "    }.get(split)   \n",
    "    results = evaluate.evaluate2(np.asarray(all_scores), np.asarray(all_labels), print_results=print_results, q_level=q_level)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c605f95e2cd732774f1813a69bb8c3fc",
     "grade": false,
     "grade_id": "cell-66bc9b1a832d14d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"metric\": \"mean\" (\"standard deviation\")\n",
      "dcg: 85.7777 (20.91925)\n",
      "dcg@03: 4.7454 (4.73538)\n",
      "dcg@05: 6.7803 (5.40121)\n",
      "dcg@10: 11.1380 (6.65006)\n",
      "dcg@20: 17.6609 (8.01651)\n",
      "ndcg: 0.6897 (0.05202)\n",
      "ndcg@03: 0.1660 (0.16215)\n",
      "ndcg@05: 0.1803 (0.13608)\n",
      "ndcg@10: 0.2151 (0.11286)\n",
      "ndcg@20: 0.2618 (0.10004)\n",
      "precision@01: 0.1400 (0.34699)\n",
      "precision@03: 0.1200 (0.19732)\n",
      "precision@05: 0.1200 (0.14967)\n",
      "precision@10: 0.1440 (0.13879)\n",
      "precision@20: 0.1510 (0.11423)\n",
      "recall@01: 0.0075 (0.02075)\n",
      "recall@03: 0.0190 (0.03542)\n",
      "recall@05: 0.0309 (0.04568)\n",
      "recall@10: 0.0659 (0.06121)\n",
      "recall@20: 0.1355 (0.10062)\n",
      "relevant rank: 110.9551 (76.60154)\n",
      "relevant rank per query: 2620.7600 (1330.38746)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/torchenv/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "## example \n",
    "# function that scores a given feature vector e.g a network\n",
    "net = nn.Linear(501, 1)\n",
    "# the evaluate method accepts a function. more specifically, a callable (such as pytorch modules) \n",
    "def notwork(x):\n",
    "    return net(x)\n",
    "# evaluate the function\n",
    "_ = evaluate_model(notwork, \"validation\", print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f71c11c5be87af7e7109a463a1e24c6c",
     "grade": false,
     "grade_id": "cell-66ae15ed8cb736b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The next cell is used to generate reproducible results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d81a93ddde3c0ae3be42eba5a6ba025d",
     "grade": false,
     "grade_id": "cell-df3d4a5ebf6dece6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# use to get reproducible results\n",
    "def seed(random_seed):\n",
    "    import random\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acd2f7fa9d402a7704d9f7f5fc1c2c89",
     "grade": false,
     "grade_id": "cell-a29483034efce729",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Section 2: Pointwise LTR (55 points) <a class=\"anchor\" id=\"pointwiseLTR\"></a>\n",
    "\n",
    "[Back to TOC](#top)\n",
    "\n",
    "Let $x \\in \\mathbb{R}^d$ be an input feature vector, containing features for a query-document pair. Let $f: \\mathbb{R}^d \\rightarrow \\mathbb{R} $ be a function that maps this feature vector to a number $f(x)$ - either a relevance score (regression) or label (classification). The data $\\{x \\}$ are treated as feature vectors and the relevance judgements are treated as the target which we want to predict. \n",
    "\n",
    "In this section, you will implement a simple Pointwise model using either a regression or classification loss, and use the train set to train this model to predict (or classify) the relevance score. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0f5f848b2a3509141e384bd4d101923",
     "grade": false,
     "grade_id": "cell-fdcb0b1bd78f6eda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Section 2.1: Neural Model (5 points)\n",
    "\n",
    "In the following cell, you will implement a simple pointwise LTR model: \n",
    "- Use a neural network to learn a Pointwise model using both a regression and a classification loss, using the relevance grades as the label. Use the following parameters: \n",
    "  - Layers: $501 (input) \\rightarrow 256 \\rightarrow o$ where $o$ is either 5 for classification or 1 for regression, where each layer is a linear layer (`nn.Linear`) with a ReLu activation function (`nn.ReLU`) in between the layers. Use the default weight initialization scheme. (Hint: use `nn.Sequential` for a one-line forward function!)\n",
    "  - Note: Do not use a `nn.Softmax` function here - it will be taken care of later!\n",
    "  - This network will also be used by other methods i.e Pairwise \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbaeb826028de6d6d7429ee18c90f455",
     "grade": false,
     "grade_id": "cell-e6ebad1d98f78bf0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (5 points)\n",
    "class NeuralModule(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        \"\"\"\n",
    "        Initializes the Pointwise neural network. \n",
    "        Input: output_dim: The dimension of the output layer. In this assignment, \n",
    "                it is either 1 (regression) or 5 (classification)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        if output_dim not in [1, 5]:\n",
    "            return \n",
    "\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(nn.Linear(501, 256), nn.ReLU(), nn.Linear(256, output_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \"\"\"\n",
    "        Takes in an input feature vector (of size 501) and produces the (regression/classification) output \n",
    "        Input: x: a [N, 501] tensor\n",
    "        Output: a [N, output_dim] tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eebff5ba2f470a05674e79514a6ba7bc",
     "grade": false,
     "grade_id": "cell-2326178594a8f44c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "point_nn_clf = NeuralModule(5)\n",
    "point_nn_reg = NeuralModule(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eebff5ba2f470a05674e79514a6ba7bc",
     "grade": false,
     "grade_id": "cell-2326178594a8f44c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "point_nn_clf = NeuralModule(5)\n",
    "point_nn_reg = NeuralModule(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "958fde08e4a9f04e633dc82bc85082dd",
     "grade": true,
     "grade_id": "cell-917f63ec6b575f59",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73bba77f886ccd469eb1b3c4370c830f",
     "grade": true,
     "grade_id": "cell-bd3bbcd6d22aa9b2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test the forward function\n",
    "n = 10\n",
    "inp = torch.rand(n, data.num_features)\n",
    "out = point_nn_clf(inp)\n",
    "### BEGIN HIDDEN TEST\n",
    "n = 20\n",
    "inp = torch.rand(n, data.num_features)\n",
    "out = point_nn_clf(inp)\n",
    "assert out.size(0) == n\n",
    "assert out.size(1) == 5\n",
    "### END HIDDEN TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5dfa481e9b325b14fdb26e39618d6169",
     "grade": true,
     "grade_id": "cell-1d92c755e64de89f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test the forward function\n",
    "n = 10\n",
    "inp = torch.rand(n, data.num_features)\n",
    "out = point_nn_reg(inp)\n",
    "### BEGIN HIDDEN TEST\n",
    "n = 20\n",
    "inp = torch.rand(n, data.num_features)\n",
    "out = point_nn_reg(inp)\n",
    "assert out.size(0) == n\n",
    "assert out.size(1) == 1\n",
    "### END HIDDEN TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.2: Loss Functions (5 points)\n",
    "Pointwise LTR algorithms use pointwise loss functions.\n",
    "Usually, the popular loss functions for pointwise LTR are:\n",
    " - Cross entropy loss for classification (3 points)\n",
    " - Regression loss (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation (3 points):**\n",
    "Implement cross entropy loss and and then cross entropy prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a82ac14d42f8800a3fcf1fe5153dd1d3",
     "grade": false,
     "grade_id": "cell-d095f3c75bd11bc3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (2 points)\n",
    "def clf_loss(output, target):\n",
    "    \"\"\"\n",
    "    Cross entropy loss - returns a single number. \n",
    "    output: (float) tensor, shape - [N, 5] \n",
    "    target: (float/long) tensor, shape - [N]. \n",
    "    \n",
    "    Hint: This function should also handle cases when target is either long/float types \n",
    "    \"\"\"\n",
    "    \n",
    "    assert output.size(0) == target.size(0)\n",
    "    assert output.size(1) == 5\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    print(type(loss(output, target.long())))\n",
    "    print(loss(output, target.long()))\n",
    "    return loss(output, target.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec3127e3b21ab74c2771110450b46559",
     "grade": true,
     "grade_id": "cell-eb43efcf784d82d9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.5910)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.6006)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.6724)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.8066)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.6386)\n",
      "your results: [1.5910069942474365, 1.600582480430603, 1.6723783016204834, 1.8065980672836304, 1.6385562419891357]\n",
      "expected results: [1.5910069942474365, 1.600582480430603, 1.6723783016204834, 1.8065979480743408, 1.6385562419891357]\n"
     ]
    }
   ],
   "source": [
    "## Test clf_loss\n",
    "g = torch.manual_seed(42)\n",
    "tests = [torch.rand(5, 5, generator=g) for _ in range(5)]\n",
    "target = torch.LongTensor([1, 2, 3, 4, 0])\n",
    "\n",
    "results = [1.5910069942474365, \n",
    "           1.600582480430603, \n",
    "           1.6723783016204834, \n",
    "           1.8065979480743408, \n",
    "           1.6385562419891357]\n",
    "\n",
    "l1 = [clf_loss(output, target).item() for output in tests]\n",
    "print(f'your results: {l1}')\n",
    "print(f'expected results: {results}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593, 0.3904],\n",
      "        [0.6009, 0.2566, 0.7936, 0.9408, 0.1332],\n",
      "        [0.9346, 0.5936, 0.8694, 0.5677, 0.7411],\n",
      "        [0.4294, 0.8854, 0.5739, 0.2666, 0.6274],\n",
      "        [0.2696, 0.4414, 0.2969, 0.8317, 0.1053]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.5910)\n",
      "1.5910069942474365\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.5910)\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[0.2695, 0.3588, 0.1994, 0.5472, 0.0062],\n",
      "        [0.9516, 0.0753, 0.8860, 0.5832, 0.3376],\n",
      "        [0.8090, 0.5779, 0.9040, 0.5547, 0.3423],\n",
      "        [0.6343, 0.3644, 0.7104, 0.9464, 0.7890],\n",
      "        [0.2814, 0.7886, 0.5895, 0.7539, 0.1952]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.6006)\n",
      "1.600582480430603\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.6006)\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[0.0050, 0.3068, 0.1165, 0.9103, 0.6440],\n",
      "        [0.7071, 0.6581, 0.4913, 0.8913, 0.1447],\n",
      "        [0.5315, 0.1587, 0.6542, 0.3278, 0.6532],\n",
      "        [0.3958, 0.9147, 0.2036, 0.2018, 0.2018],\n",
      "        [0.9497, 0.6666, 0.9811, 0.0874, 0.0041]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.6724)\n",
      "1.6723783016204834\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.6724)\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[0.1088, 0.1637, 0.7025, 0.6790, 0.9155],\n",
      "        [0.2418, 0.1591, 0.7653, 0.2979, 0.8035],\n",
      "        [0.3813, 0.7860, 0.1115, 0.2477, 0.6524],\n",
      "        [0.6057, 0.3725, 0.7980, 0.8399, 0.1374],\n",
      "        [0.2331, 0.9578, 0.3313, 0.3227, 0.0162]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.8066)\n",
      "1.8065980672836304\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.8066)\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[0.2137, 0.6249, 0.4340, 0.1371, 0.5117],\n",
      "        [0.1585, 0.0758, 0.2247, 0.0624, 0.1816],\n",
      "        [0.9998, 0.5944, 0.6541, 0.0337, 0.1716],\n",
      "        [0.3336, 0.5782, 0.0600, 0.2846, 0.2007],\n",
      "        [0.5014, 0.3139, 0.4654, 0.1612, 0.1568]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.6386)\n",
      "1.6385562419891357\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.6386)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "g = torch.manual_seed(42)\n",
    "tests = [torch.rand(5, 5, generator=g) for _ in range(5)]\n",
    "target = torch.LongTensor([1, 2, 3, 4, 0])\n",
    "for x in tests:\n",
    "    print(x)\n",
    "    print(clf_loss(x, target).item())\n",
    "    print(type(clf_loss(x, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1e1871d067d534d41585fe9d657244a",
     "grade": false,
     "grade_id": "cell-d01649f26022bf4c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (1 points)\n",
    "def clf_pred(inp, net):\n",
    "    \"\"\"\n",
    "    The output of the classifier network produces a [Nx5] output corresponding to \n",
    "    the relevance labels (each row does *not* add to 1!)\n",
    "    This function should predict the most probable relevance from the relevance labels\n",
    "    \n",
    "    inp: The input [N, num_features]\n",
    "    net: the neural network, takes in [N, num_features] and outputs [N, 5]\n",
    "    \n",
    "    return: a [N, 1] (long) tensor, the relevance labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    scores = net(inp)\n",
    "    \n",
    "    return torch.LongTensor(torch.max(scores,1)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e01b7aa6f5cebb78e604f9fa5d8da29",
     "grade": true,
     "grade_id": "cell-1f5c809567bf7f02",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your results:[3 3 2 1 2 4 4 1 3 1]\n",
      "expected:[3 3 2 1 2 4 4 1 3 1]\n"
     ]
    }
   ],
   "source": [
    "g = torch.manual_seed(42)\n",
    "def clf_(inp):\n",
    "    return torch.rand(inp.size(0), 5, generator=g)\n",
    "\n",
    "inp = torch.rand(10, 5, generator=g)\n",
    "r = np.array([3, 3, 2, 1, 2, 4, 4, 1, 3, 1])\n",
    "p = clf_pred(inp, clf_).numpy()\n",
    "print(f'your results:{p}')\n",
    "print(f'expected:{r}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6cf6191b552e4daea3f0fd4a91e15fd4",
     "grade": false,
     "grade_id": "cell-a4f04b744ef63756",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE:\n",
    "# to construct a predictor for a particular network, see this example\n",
    "# (this will be required in the next cell)\n",
    "clf_pred_fn = partial(clf_pred, net=point_nn_clf)\n",
    "# the 'net' argument doesn't need to be provided anymore!\n",
    "clf_pred_fn(torch.rand(5, data.num_features)).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e14973fb674e1e9adb553605e4e7b333",
     "grade": false,
     "grade_id": "cell-d683efd6ca306e81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Implementation (2 points):**\n",
    "Implement regression loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f2b905ddb927ed981bb294825674993",
     "grade": false,
     "grade_id": "cell-c024ed97d7100038",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (2 points)\n",
    "def reg_loss(output, target):\n",
    "    \"\"\"\n",
    "    Regression loss - returns a single number. \n",
    "    Make sure to use the TODO loss!\n",
    "    output: (float) tensor, shape - [N, 1] \n",
    "    target: (float) tensor, shape - [N]. \n",
    "    \"\"\"\n",
    "    assert target.dim() == 1\n",
    "    assert output.size(0) == target.size(0)\n",
    "    assert output.size(1) == 1\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Remove axes of length one from the output\n",
    "    output = output.squeeze() \n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    return criterion(output, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "064dde728a201a97f97ca266c8641a0e",
     "grade": true,
     "grade_id": "cell-24edd9d567aac9da",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your results:[4.800000190734863, 3.0, 7.599999904632568, 5.400000095367432, 0.6000000238418579]\n",
      "expected:[4.800000190734863, 3.0, 7.599999904632568, 5.400000095367432, 0.6000000238418579]\n"
     ]
    }
   ],
   "source": [
    "## Test reg_loss\n",
    "g = torch.manual_seed(42)\n",
    "output = [torch.randint(low=0, high=5, size=(5, 1), generator=g).float() for _ in range(5)]\n",
    "target = torch.randint(low=0, high=5, size=(5,), generator=g).float()\n",
    "\n",
    "l = [reg_loss(o, target).item() for o in output]\n",
    "r = [4.800000190734863, \n",
    "     3.0, \n",
    "     7.599999904632568, \n",
    "     5.400000095367432, \n",
    "     0.6000000238418579]\n",
    "print(f'your results:{l}')\n",
    "print(f'expected:{r}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0eddb61dde344891ea7efc8fdd67752f",
     "grade": false,
     "grade_id": "cell-0977a61ec0cfa7ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Implementation (45 points):**\n",
    "Now implement a wrapper for training a pointwise LTR, that takes the model and the loss function as input and trains the model.\n",
    "\n",
    "**Rubric:**\n",
    " - Network is trained for specified epochs, and iterates over the entire dataset and (train) data is shuffled : 5 points\n",
    " - Evaluation on the validation set: 5 points\n",
    " - Training (e.g optimizer, zero_grad, backward): 10 points\n",
    " - Appropriate loss function & prediction function: 5 points\n",
    " - Both classification / regression models handled appropriately: 5 points\n",
    " - Performance as expected: 15 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8dbfd2a686ecc7ab254a4e5e9b332119",
     "grade": false,
     "grade_id": "cell-9361533c572e304b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (45 points)\n",
    "def train_pointwise(net, loss, params):\n",
    "    \"\"\"\n",
    "    This function should train a Pointwise network, \n",
    "    trained based on the loss (either \"clf\" / \"reg\"). \n",
    "    \n",
    "    The network is trained using the Adam optimizer\n",
    "        \n",
    "    \n",
    "    Note: Do not change the function definition! \n",
    "    \n",
    "    \n",
    "    Hints:\n",
    "    1. Use the LTRData class defined above\n",
    "    2. You will have to construct a partial function if loss=\"clf\" \n",
    "       before using it in evaluate_model() (see cells after the defn of clf_pred)\n",
    "    \n",
    "    net: the neural network to be trained\n",
    "    \n",
    "    loss: one of \"clf\" or \"reg\"\n",
    "    \n",
    "    params: params is an object which contains config used in training \n",
    "        (eg. params.epochs - the number of epochs to train). \n",
    "        For a full list of these params, see the next cell. \n",
    "    \n",
    "    Returns: a dictionary containing: \"metrics_val\" (a list of dictionaries) and \n",
    "             \"metrics_train\" (a list of dictionaries). \n",
    "             \n",
    "             \"metrics_val\" should contain metrics (the metrics in params.metrics) computed\n",
    "             after each epoch on the validation set (metrics_train is similar). \n",
    "             You can use this to debug your models.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    assert loss in {\"clf\", \"reg\"}\n",
    "    \n",
    "    val_metrics_epoch = []\n",
    "    train_metrics_epoch = []\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    epochs = params.epochs\n",
    "    lr = params.lr\n",
    "    batch_size = params.batch_size\n",
    "    metrics = params.metrics\n",
    "    \n",
    "    train_dl = DataLoader(LTRData(data, \"train\"), batch_size=batch_size, shuffle=True)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    if loss == 'clf':\n",
    "        pred_fn = partial(clf_pred, net=net)\n",
    "        loss_fn = clf_loss\n",
    "    else:\n",
    "        pred_fn = net\n",
    "        loss_fn = reg_loss\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for (x, y) in train_dl:\n",
    "            pred = net(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        m_trn = evaluate_model(pred_fn, \"train\", batch_size=batch_size)\n",
    "        train_metrics_epoch.append({m: m_trn[m] for m in metrics})\n",
    "        \n",
    "        m_val = evaluate_model(pred_fn, \"validation\", batch_size=batch_size)\n",
    "        val_metrics_epoch.append({m: m_val[m] for m in metrics})\n",
    "        \n",
    "    return {\n",
    "        \"metrics_val\": val_metrics_epoch,\n",
    "        \"metrics_train\": train_metrics_epoch\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to test your code!\n",
    "pointwise_test_params = Namespace(epochs=1, \n",
    "                    lr=1e-3,\n",
    "                    batch_size=256,\n",
    "                   metrics={\"ndcg\"})\n",
    "# uncomment to test your code\n",
    "## train a regression model\n",
    "# met_reg = train_pointwise(point_nn_reg, \"reg\", pointwise_test_params)\n",
    "## train a classification model\n",
    "# met_clf = train_pointwise(point_nn_clf, \"clf\", pointwise_test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "738eaae8abdea0f21d248a0d677bc424",
     "grade": false,
     "grade_id": "cell-27ec0e0dd8a5d98d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The next cell is used to generate reproducible results which should be submitted with the assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a485ad0b3f14de6ee384fa6b42ab36f",
     "grade": false,
     "grade_id": "cell-11e8cbc591a51256",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def create_results(net, train_fn, prediction_fn, results_file, *train_params):\n",
    "    \n",
    "    print(\"Training Model\")\n",
    "    metrics = train_fn(net, *train_params)\n",
    "    net.eval()\n",
    "    test_metrics, test_qq = evaluate_model(prediction_fn, \"test\", print_results=True, q_level=True)\n",
    "    \n",
    "    \n",
    "    test_q = {}\n",
    "    for m in {\"ndcg\", \"precision@05\", \"recall@05\"}:\n",
    "        test_q[m] = test_qq[m]\n",
    "    \n",
    "    with open(results_file, \"w\") as writer:\n",
    "        json.dump({\n",
    "            \"metrics\": metrics,\n",
    "            \"test_metrics\": test_metrics,\n",
    "            \"test_query_level_metrics\": test_q,\n",
    "        }, writer, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5926b542770cebafc36574bbff9b7d3e",
     "grade": false,
     "grade_id": "cell-16ed543545863f61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now use the above functions to generate your `json` files for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eef82389f05e60a59c9bddefc6570264",
     "grade": false,
     "grade_id": "cell-cb8314e4e579adac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6bc9ae5a2f4af89c6623ca9e0b69b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (test):   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"metric\": \"mean\" (\"standard deviation\")\n",
      "dcg: 113.0421 (25.27161)\n",
      "dcg@03: 21.6468 (8.26373)\n",
      "dcg@05: 27.7049 (10.58726)\n",
      "dcg@10: 36.5582 (13.01399)\n",
      "dcg@20: 46.9664 (14.73442)\n",
      "ndcg: 0.8719 (0.05406)\n",
      "ndcg@03: 0.7365 (0.22878)\n",
      "ndcg@05: 0.7141 (0.20548)\n",
      "ndcg@10: 0.6936 (0.17153)\n",
      "ndcg@20: 0.6822 (0.14087)\n",
      "precision@01: 0.8462 (0.36080)\n",
      "precision@03: 0.7493 (0.30788)\n",
      "precision@05: 0.6786 (0.28639)\n",
      "precision@10: 0.5735 (0.23908)\n",
      "precision@20: 0.4449 (0.19397)\n",
      "recall@01: 0.0380 (0.02790)\n",
      "recall@03: 0.1009 (0.06092)\n",
      "recall@05: 0.1494 (0.08568)\n",
      "recall@10: 0.2458 (0.11527)\n",
      "recall@20: 0.3666 (0.13992)\n",
      "relevant rank: 62.6742 (61.18353)\n",
      "relevant rank per query: 1612.9231 (957.11789)\n"
     ]
    }
   ],
   "source": [
    "seed(42)\n",
    "params_regr = Namespace(epochs=11, \n",
    "                    lr=1e-3,\n",
    "                    batch_size=256,\n",
    "                    metrics={\"ndcg\", \"precision@05\", \"recall@05\"})\n",
    "\n",
    "pointwise_regression_model = NeuralModule(1)\n",
    "create_results(pointwise_regression_model, \n",
    "               train_pointwise, \n",
    "               pointwise_regression_model,\n",
    "               \"./pointwise_regression.json\", \n",
    "               \"reg\", params_regr)\n",
    "# persist models\n",
    "torch.save(pointwise_regression_model.state_dict(), \"./pointwise_regr_wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ddac4c7614df42d2655e2304eba1c21",
     "grade": false,
     "grade_id": "cell-8b25e13a53ad95ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e83eb26bb2846e08fb8d91018a636ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.6237, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.4611, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.4331, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.3563, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.3497, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.3081, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2618, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.3492, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2810, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.3347, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2269, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1802, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2085, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2574, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2158, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2651, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2009, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1691, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2191, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1367, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1793, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1433, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2511, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2235, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2135, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2041, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1690, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.3289, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2431, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2456, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2092, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1733, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1768, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2042, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2372, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1631, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2045, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2083, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2432, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2242, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1695, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2690, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1847, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1582, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2036, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1192, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2370, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1241, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1683, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1507, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1205, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1567, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1618, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1985, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0918, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1908, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1688, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1630, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1432, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1201, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1446, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1683, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2583, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1045, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1783, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1101, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1092, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2207, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0960, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1646, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2323, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1134, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1319, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2018, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1499, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2724, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1177, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2213, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1962, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1398, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1311, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2243, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1765, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2357, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1718, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1184, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0885, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1457, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1134, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1709, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1735, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1637, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1805, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1445, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1992, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1337, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1291, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1373, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1748, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1207, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1271, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1205, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1704, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1212, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1243, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1874, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1070, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1119, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1171, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1975, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1821, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2178, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1882, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1763, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0893, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1729, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1427, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1985, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1510, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1797, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1710, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1396, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2239, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1038, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2062, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0841, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1581, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1290, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1129, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1341, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0784, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1269, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1519, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1279, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.1721, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2298, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2321, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1588, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2175, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1868, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1903, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1065, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2477, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2018, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1112, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1671, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1835, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1223, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1165, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1453, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2145, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1520, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1792, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1266, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1897, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1268, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1072, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0989, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0731, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1186, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1698, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0847, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1467, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2031, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1706, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1509, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1067, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1873, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1751, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1389, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1724, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1635, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0855, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1100, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0872, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1715, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2273, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1106, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1574, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1913, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1493, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1050, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1143, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1071, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1323, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1942, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1893, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1829, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1547, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1847, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1051, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1458, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1610, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1307, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1814, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1130, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1620, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1574, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1359, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2632, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1545, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0898, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1951, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1806, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0855, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0679, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1070, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1448, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1215, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1871, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1968, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1723, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2074, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1448, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1694, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1844, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1759, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1406, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1268, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1213, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1400, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1250, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1459, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2535, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1695, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1682, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1556, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0651, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0434, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1759, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1453, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1707, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1663, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1228, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0744, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1622, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1829, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1286, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1647, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1791, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1111, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1434, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1145, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2010, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1302, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1270, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1581, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1257, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1502, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1565, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1429, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1354, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1576, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1430, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1315, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1401, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1080, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1599, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1408, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0452, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1445, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1327, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1499, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0813, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1414, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1450, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1153, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1373, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1827, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1618, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0867, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1966, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1777, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1264, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1320, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1039, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1545, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1526, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1656, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1302, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1192, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1525, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1372, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1527, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0754, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1885, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2709, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0691, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1111, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1414, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1579, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1445, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1353, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1073, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1386, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1123, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1705, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1267, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1777, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0885, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1644, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1474, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1629, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1181, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0964, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0858, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1696, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1304, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1189, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1924, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1645, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1836, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1124, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1404, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0866, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2073, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1509, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1002, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0690, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1923, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1144, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1606, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1079, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1384, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1620, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1219, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0982, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1202, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1040, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0567, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1176, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1836, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1308, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.1071, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1133, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0349, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1269, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0980, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1003, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0861, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1867, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1626, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9939, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0687, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2017, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1487, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1948, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1246, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0711, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0846, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1154, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1009, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1371, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0563, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1473, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1073, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1717, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1557, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0915, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0491, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0903, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1114, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1155, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1351, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0589, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1613, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1531, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1129, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0758, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0707, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1188, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1017, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2159, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0589, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1020, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0984, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0822, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0872, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1233, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1151, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1062, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1638, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0468, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0928, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1195, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1851, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1763, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1693, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1215, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0522, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0798, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1880, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2224, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0488, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0876, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1697, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1576, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1289, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1174, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1282, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1255, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1932, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1435, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1221, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1294, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0798, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0864, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1168, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0993, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1470, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0842, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1354, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1588, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1022, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1166, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1228, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1359, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0950, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1662, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0840, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1406, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1727, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1169, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1216, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1025, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1746, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0858, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1952, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1306, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0616, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0516, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1301, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1192, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1540, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1262, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1761, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0823, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0704, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1189, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0553, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0609, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1574, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1587, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0952, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1293, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1164, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1332, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1292, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1313, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1552, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0734, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0977, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0775, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1434, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0674, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1424, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1627, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1112, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1715, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0906, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0624, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1020, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1022, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1264, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1176, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1555, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1450, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0882, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0485, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1214, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1364, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1612, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1844, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1137, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1067, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1882, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0973, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2032, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0909, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0811, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1223, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1080, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0600, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1612, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1866, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0722, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1333, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0955, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1886, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1299, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1618, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0976, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1421, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0823, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2269, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0655, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1394, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1050, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0565, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0936, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1758, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1172, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1418, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1351, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1656, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1587, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0444, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1767, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0765, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1284, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1523, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1379, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0907, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1523, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1093, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1524, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0574, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0821, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1026, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1142, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1769, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1471, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1307, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0422, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1309, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0853, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1762, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0880, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1463, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0627, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1529, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1806, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1478, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1795, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1792, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1045, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1172, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1503, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1266, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1082, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1356, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1265, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1288, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1433, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1036, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0948, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1163, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0384, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1364, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1641, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0665, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1479, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1206, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0739, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1376, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1147, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0656, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1448, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1569, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1614, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1854, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0569, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0874, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1639, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1105, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0459, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0513, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1266, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1672, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1057, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1329, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0423, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0933, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2213, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1375, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1423, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1251, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1577, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1280, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1723, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1841, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0768, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1335, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2016, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1382, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1384, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1497, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1414, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1126, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0410, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1041, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0963, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1607, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0817, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1216, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1454, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1725, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0875, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0894, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1313, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0679, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1441, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1543, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1366, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2235, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1291, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2187, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1085, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2088, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0818, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0905, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1573, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0929, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0981, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0676, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0770, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1428, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0936, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0718, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1923, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1127, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1061, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1250, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0262, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1022, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0797, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1826, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1313, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.1168, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1173, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1187, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1502, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1201, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2152, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0897, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1611, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0947, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1072, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1583, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1772, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1060, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0567, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0660, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1336, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1580, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1828, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1594, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0874, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0643, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0965, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1198, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0195, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1060, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1265, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1287, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1516, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1290, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0971, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1652, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0997, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0537, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0698, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0889, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0785, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1355, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0905, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.1770, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1963, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0751, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0968, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1675, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0980, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1187, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0950, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1408, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1235, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0689, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1443, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0702, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0894, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1599, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1133, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0830, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1090, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0892, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1428, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1545, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1411, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0256, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1482, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0640, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0829, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0495, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1353, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1122, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1453, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1583, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1111, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0714, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1084, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0749, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0421, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1013, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0984, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2089, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0861, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1047, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0887, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1349, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1667, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1208, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1027, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1155, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1364, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1191, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0830, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1040, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0925, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0817, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0772, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0677, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1404, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1304, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0795, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1118, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1229, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1008, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1395, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1508, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1951, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0996, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1391, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1567, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1099, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1078, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1092, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0810, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1396, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0000, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1929, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0677, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1266, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1333, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2112, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0466, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0237, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1047, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1448, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2074, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1455, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1039, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0734, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1033, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1502, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1442, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2577, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0835, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1142, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1217, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0392, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1483, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0520, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0647, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1063, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0748, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0650, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0940, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1504, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1810, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1163, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1312, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1674, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0990, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1666, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1686, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1244, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1155, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0993, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0342, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1680, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1125, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1482, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0914, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1132, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0773, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1175, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0903, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0878, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0491, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1253, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1158, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0806, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0533, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1478, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1436, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0931, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0669, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1538, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0766, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1363, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1333, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1572, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0826, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1091, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1001, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9953, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1626, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1524, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1150, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1107, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1521, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1879, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1036, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0918, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.1504, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1395, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1193, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1436, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0953, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1664, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1343, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0507, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1458, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0799, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0799, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1514, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0509, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2153, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0816, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0858, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2221, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1512, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1143, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0533, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1222, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0982, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1011, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1080, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1098, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1146, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0981, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0976, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1020, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1954, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1571, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0607, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0798, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1310, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1451, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0661, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1360, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0721, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0833, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1063, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0923, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1075, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0829, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0793, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0586, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0551, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0720, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0662, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1315, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1259, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0616, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0863, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1587, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0404, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0903, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0766, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0705, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1640, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0724, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1473, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1011, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1153, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0701, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0864, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0786, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1022, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9918, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0738, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1571, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0724, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0198, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1550, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1924, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1092, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0636, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0774, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1347, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0052, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1643, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0831, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1002, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1101, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0606, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0666, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9552, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1010, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1654, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1181, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1283, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1041, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1434, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0883, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0921, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1432, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1346, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1383, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0563, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0963, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1378, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1244, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0910, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1086, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0609, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0731, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0927, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0965, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1033, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1577, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0393, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9851, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0480, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1306, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1589, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2014, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0999, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1297, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1719, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1064, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0770, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0278, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1041, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1265, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1609, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0929, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1434, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0603, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0545, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1001, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1817, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1227, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0402, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0611, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0709, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0638, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0870, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1076, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1236, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0715, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1120, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1352, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0757, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0880, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1071, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0713, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1183, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1658, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0254, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0696, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1896, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1218, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1042, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1055, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0616, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1171, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0457, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0992, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0500, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0666, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2043, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0620, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0943, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0131, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1107, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1032, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1280, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0762, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1487, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0728, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1575, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1240, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0856, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1176, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0870, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1366, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0733, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0911, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0300, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0554, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1594, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0993, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1417, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1073, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1727, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1716, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1444, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0640, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0458, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1412, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0357, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0896, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0570, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0430, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1033, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0850, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1166, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1366, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0644, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1480, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1856, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1074, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0400, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0866, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0735, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0745, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0811, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1539, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0970, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0310, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0870, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0499, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0336, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1738, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1449, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1002, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1132, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1149, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0955, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1013, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0832, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1125, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0628, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0341, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2169, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1264, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0607, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0254, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1468, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1102, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0954, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0947, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1061, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0477, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1010, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0669, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1355, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0402, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1581, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0874, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0759, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1315, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1106, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0727, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0536, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0365, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0661, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1471, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0171, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0558, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1106, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0933, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1019, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1047, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1534, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1589, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0789, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0512, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0593, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0942, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0816, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1437, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0640, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1410, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1022, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0887, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0365, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1522, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1126, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1435, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1614, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0795, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0363, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0929, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1489, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1590, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1058, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1163, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0302, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0789, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0861, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1103, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1789, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1214, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1015, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1514, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0838, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0461, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0826, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1012, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0963, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1019, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1034, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1122, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0963, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0933, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0765, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1080, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1096, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0542, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1355, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0027, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0745, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0952, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1389, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0735, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1116, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0170, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1146, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0604, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0902, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0449, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1024, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0897, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0287, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0816, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0793, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1243, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0928, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1372, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0560, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1091, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1060, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0798, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1464, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0787, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0792, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0752, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1240, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0713, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0438, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0606, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0436, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.1523, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0419, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1416, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0847, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1130, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0802, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1514, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0478, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0457, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0455, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1249, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0840, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1123, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1297, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0735, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0250, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1034, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1632, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0294, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9899, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0954, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1610, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0957, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1426, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1008, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1312, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1455, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0373, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1141, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1256, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0985, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1177, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0969, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0756, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0517, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0559, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0996, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0925, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1164, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1179, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1657, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0371, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1210, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1214, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0298, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1153, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1051, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0905, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1554, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0942, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1092, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0401, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1767, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0363, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1573, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0442, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1842, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0838, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1053, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1562, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1182, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1245, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1563, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0690, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1081, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1068, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0604, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1205, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1159, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0739, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1350, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1024, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0782, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0810, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0912, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0375, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0597, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0889, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1080, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0741, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0462, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0866, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1636, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0415, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0645, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0935, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1766, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1123, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0754, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1355, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1590, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0614, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0741, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0728, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1937, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0537, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0792, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1343, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1282, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0535, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1583, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9925, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1362, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1136, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0508, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0851, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0688, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1683, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1611, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0473, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0680, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1641, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0925, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0586, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1019, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0909, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1014, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0959, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1155, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0817, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0907, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0720, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1111, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2198, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0312, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0661, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0865, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0711, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1325, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1417, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0577, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1275, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0607, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0502, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1323, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1099, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1241, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0780, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1999, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0239, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0836, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1191, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0950, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1256, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9729, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0816, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1802, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.1660, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1045, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1026, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1357, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0953, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1985, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0096, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1264, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0464, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0950, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0982, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1600, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1208, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1376, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0754, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0918, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0302, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1328, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1041, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1507, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1857, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0934, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0471, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0633, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1636, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0673, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0624, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0939, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1166, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0856, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0276, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0720, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1381, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1130, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0883, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1145, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0485, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1306, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0795, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1110, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.1284, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1254, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0721, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0606, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0314, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1483, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1054, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0870, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1083, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0740, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1119, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0452, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1348, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0520, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0876, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1650, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1223, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9899, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0400, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0450, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1154, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0362, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0992, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0470, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0535, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0306, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0687, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0802, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0422, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0331, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2044, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0757, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1699, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1006, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0550, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1174, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1039, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0895, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1251, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0694, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1093, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0987, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0453, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0842, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1201, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1146, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0766, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1182, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0204, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1059, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0932, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1190, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0799, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1236, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0893, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1024, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0351, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0521, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1127, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0426, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1411, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0815, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1536, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1037, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1070, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0399, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1201, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0836, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0902, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0884, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0058, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0857, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0699, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0619, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1176, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1065, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1029, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1022, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1576, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0897, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0600, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1015, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0853, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0608, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0376, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0905, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0953, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0705, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0522, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0665, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0548, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0813, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1543, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1593, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0588, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1431, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1011, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0693, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0103, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0936, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0867, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1539, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1060, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0628, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0576, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1501, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0272, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0889, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0333, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1385, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1085, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0804, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1166, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0638, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0379, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0533, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0742, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0805, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0005, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1714, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0701, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0657, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1136, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0322, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0952, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0394, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0966, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0439, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1088, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0828, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0215, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0238, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0049, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0634, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0722, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0095, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0844, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1473, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1235, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0874, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0698, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1293, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1074, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0616, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1641, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0748, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0096, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1081, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1533, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0604, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1470, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1645, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0777, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1022, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0582, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1406, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0751, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1679, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0885, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1000, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1009, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1472, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1671, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0201, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0959, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1231, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0992, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0399, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1007, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0879, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0768, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0589, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1463, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0455, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0658, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0598, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1164, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0752, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1375, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1039, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0249, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1095, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0809, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1537, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0921, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1492, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0470, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1202, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0332, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0907, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0828, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0521, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1083, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1538, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1459, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1330, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0593, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0347, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0659, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0400, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0683, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1235, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1133, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0296, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0420, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1003, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0775, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1532, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0752, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0803, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0442, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0642, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0134, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0892, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0545, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0246, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0711, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0855, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0853, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0857, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0775, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1208, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1363, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0399, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1280, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0048, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0688, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0355, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0971, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0885, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0836, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0901, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0778, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0443, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1006, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0531, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1211, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1165, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0822, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0443, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9914, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0284, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0948, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1156, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0519, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0420, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0901, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0981, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0598, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0840, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1275, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0659, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0658, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0029, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0571, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0298, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0049, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0974, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0720, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0916, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1315, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1541, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9899, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1826, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1006, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0599, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1251, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1390, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0288, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1533, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0737, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1060, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0597, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0678, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0482, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0532, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0880, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0741, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0396, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1276, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0292, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0770, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0350, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1146, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0771, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1051, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1479, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0755, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0718, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0070, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1007, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1639, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0226, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1419, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0758, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0521, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0764, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0808, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1357, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0286, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0839, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1007, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1089, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0633, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1256, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1304, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1353, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1252, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1905, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0477, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0379, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1133, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1112, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0711, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0980, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0549, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1833, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1153, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9979, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0879, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1367, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0652, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0936, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0545, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0081, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0609, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1305, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0326, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0700, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0793, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0732, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1180, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1499, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0545, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0446, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0426, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0289, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1311, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0170, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0708, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0841, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0666, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0333, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0899, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0484, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1250, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0600, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0656, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0901, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1213, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0620, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0457, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0289, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1052, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1474, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1038, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0917, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0908, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1069, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0451, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0985, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1220, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1097, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1445, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0951, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0791, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0463, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0376, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0675, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0763, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0761, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0529, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1169, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1120, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0931, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1041, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0807, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0400, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0895, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0615, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0743, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1072, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0897, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0584, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0815, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0497, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0408, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0435, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0679, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0818, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0899, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0222, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0988, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0480, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0461, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0271, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1002, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0001, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1040, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0588, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0999, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0641, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0322, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0279, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0937, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9928, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1571, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1389, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0688, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1271, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0556, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0789, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1292, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0634, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9984, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0849, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0866, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0120, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0822, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0187, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0354, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1139, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1357, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0728, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1034, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0519, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1393, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1260, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0937, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0230, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1837, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0606, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0884, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0608, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1569, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0889, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1287, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0429, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0232, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0380, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0789, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0787, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0261, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0386, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1483, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1386, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0221, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0742, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1355, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0489, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0858, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0872, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0811, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0767, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0506, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1326, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0644, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0800, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0770, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0365, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0142, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0981, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0801, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1094, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1066, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1237, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0835, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1101, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0770, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0827, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1217, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0741, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0385, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0378, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0605, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0476, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0687, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0556, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1582, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0925, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0717, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0066, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0334, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0874, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0172, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0188, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0691, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1095, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0771, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1054, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2073, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1049, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0843, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0540, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0585, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0932, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0876, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1398, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0765, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0323, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0263, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0955, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1127, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1148, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0552, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0955, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0613, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1001, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0887, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1233, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0320, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0660, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0796, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0672, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0442, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0325, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0593, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0803, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0522, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0672, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1064, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0621, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0953, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0205, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1453, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0910, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1231, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0816, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0094, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1953, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0771, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0550, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0199, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0633, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0786, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0854, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0362, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0547, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0319, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0252, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1168, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1204, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0567, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2434, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1113, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0844, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1015, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9995, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0356, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0630, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0895, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1314, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0542, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1589, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0795, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0576, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1188, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0259, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1308, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0721, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1120, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0773, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0728, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0698, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1159, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0474, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1436, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0828, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0785, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1109, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0325, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1258, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0269, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0555, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0676, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0679, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0809, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0583, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0635, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1292, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0434, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0305, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0204, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0892, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0654, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1180, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0577, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9875, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0948, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0469, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0025, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0689, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0924, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1060, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0932, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1149, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0123, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9864, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1428, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0602, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0594, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1371, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1171, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0134, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1392, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0676, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0855, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0878, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0956, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1133, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0749, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1182, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1474, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0384, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0505, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1108, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0596, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0469, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0315, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1067, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0622, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0153, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0823, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0318, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9696, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9752, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1376, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0910, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0522, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0795, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0548, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0881, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0820, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1113, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0922, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0335, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0496, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0201, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0815, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0883, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1515, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0568, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0903, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0643, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0394, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0124, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0847, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0659, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9972, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0590, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0650, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0583, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1024, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0319, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0818, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1002, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0897, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0534, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1226, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0195, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9509, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0660, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0759, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1088, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0443, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0904, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.1049, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1096, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1098, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0130, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0326, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0682, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1059, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2061, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9562, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0474, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0825, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1058, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0383, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0736, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0298, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0516, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0761, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1254, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0846, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0621, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0730, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0578, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0944, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0711, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0224, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0274, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0705, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0693, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0399, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0678, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0689, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0596, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0625, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1473, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0875, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0723, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1200, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0593, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1259, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1312, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0871, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1292, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0395, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0605, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0383, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0639, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1652, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0795, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1038, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0697, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1575, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0669, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0771, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0943, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0037, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0851, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0531, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1007, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0794, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9809, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0780, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0154, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0515, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0105, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0210, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0975, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0707, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1437, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0223, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0532, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0998, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0227, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0993, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0048, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1338, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0823, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0969, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0067, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0492, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0990, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9939, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0900, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0996, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1038, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0065, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9864, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0560, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0497, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0849, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0500, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0962, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0707, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0675, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0587, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0033, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1034, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9907, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0784, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0778, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0685, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0711, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0769, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0805, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9624, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1443, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0547, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9883, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1120, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0804, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9883, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9995, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0362, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0254, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0270, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0430, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0854, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9544, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1814, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0254, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0659, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0980, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0194, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0774, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1130, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0862, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0546, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0360, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0348, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1264, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0429, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0491, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0611, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0839, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0534, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1174, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0938, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1310, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0801, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0189, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0475, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0452, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0366, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1042, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0727, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0830, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0450, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0273, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9736, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0295, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0739, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0665, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0746, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0632, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0503, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0707, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0618, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0054, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0492, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1014, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0675, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0474, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0394, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0814, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0709, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0551, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0259, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0630, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0292, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0332, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0397, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0578, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0467, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0781, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1086, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9895, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0550, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9671, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1568, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0547, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1361, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0997, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1368, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1010, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1283, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0998, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0029, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0708, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0892, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0825, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0149, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0741, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0572, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1163, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0883, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9703, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0898, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0962, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0691, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0503, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1460, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0567, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0297, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1075, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0173, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0582, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0006, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0269, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1066, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0860, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0406, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1455, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1327, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0143, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0671, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0640, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1139, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0298, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9473, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0753, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0679, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1217, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1842, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0396, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0446, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0544, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0050, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0276, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0944, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0714, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0768, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1490, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0533, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0943, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1150, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1320, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0110, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0382, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1024, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1242, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0638, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0543, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0623, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0868, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9869, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9596, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0344, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1478, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1092, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0370, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1545, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0104, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0773, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1061, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0840, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0980, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1387, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0294, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0443, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0053, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1062, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0512, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1176, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0287, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9855, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1372, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0681, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0999, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1179, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0578, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0409, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0791, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0770, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1397, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0841, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0218, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0351, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1574, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0928, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0249, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0974, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0337, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0449, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9955, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1261, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0615, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9886, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0590, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1092, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0560, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0989, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0939, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0742, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9967, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0998, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0337, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1111, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0765, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0768, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.1311, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0669, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1266, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0096, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9901, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0981, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0594, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0513, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0664, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0107, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0682, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0545, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0913, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0268, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0350, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0169, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0359, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0687, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1347, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1004, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0701, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0390, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0797, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0854, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0862, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1068, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0894, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0869, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0346, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0950, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0672, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0631, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0542, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0260, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1204, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0024, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1020, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9916, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0780, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0423, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0767, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0896, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0448, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0876, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1152, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9993, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0289, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0198, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0649, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9676, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1226, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0242, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1046, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0700, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0728, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0545, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9752, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0577, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0675, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0174, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9872, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0084, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0311, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0661, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0645, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9739, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0533, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0937, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0705, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0520, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0134, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9788, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1153, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1089, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0414, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9727, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0520, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1286, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0941, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0275, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0278, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1375, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0307, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0572, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0438, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0899, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0852, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0439, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1203, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0284, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0639, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0599, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1227, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0325, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0232, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1214, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0696, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0888, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0824, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0798, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0639, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0786, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0496, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0675, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0704, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1128, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1084, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9880, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1194, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1137, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0833, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1065, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0096, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1238, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0739, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9746, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0252, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0340, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9898, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0557, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0712, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0717, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1084, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0379, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0982, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0154, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0949, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9833, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0541, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0259, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1189, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0229, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0786, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0403, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0828, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0264, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1031, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0510, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0371, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1281, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0964, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9964, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0386, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1767, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0079, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0170, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0303, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0130, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1076, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0465, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9887, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0692, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0423, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0226, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0457, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1641, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0716, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0705, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0935, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1316, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1159, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9743, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1050, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0042, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0901, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0743, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0653, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0454, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0474, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0262, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0113, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0540, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0157, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1295, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0413, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0300, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0191, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0051, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0494, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0540, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0474, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9733, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0321, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9965, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0868, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0856, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0587, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0364, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1650, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0276, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0989, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0711, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1341, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0767, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0709, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0917, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0792, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0228, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1010, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0349, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0799, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0069, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0827, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0335, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0647, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0011, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0916, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0525, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0659, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0076, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1020, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0499, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1041, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9960, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0929, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0935, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9659, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1009, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0605, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0439, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9897, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0632, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9713, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0920, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0912, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0401, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0340, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0563, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0365, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0456, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0451, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0775, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0750, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0220, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1031, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0994, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0983, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0139, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9946, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0585, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0222, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0346, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1106, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0734, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0628, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0109, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0638, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0458, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0406, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1078, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1034, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0675, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0633, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0019, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0892, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0798, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0666, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0613, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1297, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0624, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1075, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0747, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1551, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0645, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0677, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0447, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0264, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0488, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9707, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1603, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0135, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0894, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1033, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1445, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1213, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0691, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0949, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0505, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0628, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9869, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0206, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0483, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0553, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0461, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0580, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1817, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0352, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1116, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0009, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0098, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0682, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0649, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0382, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0082, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9915, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0521, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1263, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0241, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0689, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0965, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1432, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9500, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1106, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0430, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0646, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0131, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0496, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0909, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0358, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0344, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0419, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9909, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0701, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0558, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0605, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1000, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1151, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0734, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1162, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0439, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0374, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0345, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0126, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9850, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0621, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0609, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1558, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0070, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0404, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0198, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0289, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0922, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0412, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0742, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0100, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0784, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0026, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9692, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0648, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0599, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0289, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1272, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0050, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0222, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0294, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0170, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1061, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0766, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0488, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0576, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0516, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0414, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0734, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0695, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0213, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9719, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0694, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0755, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0774, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0710, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0504, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9652, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0618, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9995, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0955, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0632, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0970, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0325, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0705, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1021, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0396, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0444, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0285, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9863, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0917, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1184, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0066, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0472, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0360, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0250, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1101, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9977, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0270, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0957, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0550, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0522, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0482, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0312, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0568, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0258, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0104, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9985, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9679, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0461, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9741, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0072, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1815, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0050, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0215, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0580, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0713, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9963, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0695, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0014, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0159, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1069, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0515, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0335, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0907, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0782, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0481, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1210, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1106, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0188, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0779, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0124, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9753, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0623, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0719, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9905, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0287, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0176, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0043, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0333, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0056, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0505, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1009, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0470, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0447, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0511, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0046, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0748, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0744, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1517, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1170, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9944, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0215, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0206, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0226, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1250, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0672, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0706, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0169, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0209, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0290, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0575, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0019, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0941, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0719, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0504, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9868, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0265, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9970, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1198, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0785, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0303, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1321, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9935, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0931, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0826, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0508, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0065, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0995, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9524, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0790, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9906, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1163, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0236, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9985, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1007, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0992, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1147, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0553, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0130, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0036, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0306, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0617, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9917, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0816, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0934, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0797, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0210, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0673, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0434, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0310, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0857, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0187, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0671, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9695, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0648, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0769, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0406, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9784, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0808, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0139, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9824, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0285, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0816, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0900, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0551, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1259, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9702, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0921, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0540, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0775, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9946, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0084, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0370, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9945, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1179, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1339, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9853, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9832, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0183, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0617, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0286, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9889, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1574, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.2361, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0970, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9914, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0754, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0863, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0520, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1078, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0043, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9624, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1261, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0581, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0662, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9995, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0310, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9988, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0656, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0244, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0123, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0174, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1051, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0029, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0352, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0398, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0367, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9989, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1102, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0918, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0229, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0619, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1119, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1083, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0830, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0637, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0924, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0527, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0511, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0533, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0548, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0521, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0503, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9949, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0627, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0324, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0469, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9645, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1018, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0430, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1011, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9692, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0236, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0717, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0567, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0506, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0353, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0935, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0641, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0791, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0952, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0769, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0264, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0652, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0104, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0469, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0551, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0048, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1019, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0246, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0256, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0762, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0022, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0863, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0468, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0197, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1022, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0551, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1127, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0455, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0788, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9828, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0202, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0219, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0977, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0094, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0967, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0687, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0284, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0066, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9964, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9749, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9745, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1348, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0462, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0864, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0407, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9939, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9436, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0624, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1130, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0980, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1259, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0385, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0497, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0921, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0035, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0754, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0590, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9905, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0481, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0501, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9851, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0228, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1057, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0099, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1515, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0398, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0161, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0690, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0649, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0012, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0422, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0012, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0110, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9912, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1348, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1179, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9699, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0268, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9923, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0578, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0583, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0777, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0868, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0983, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0365, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0429, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0482, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0419, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0371, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0504, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9922, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0295, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0457, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0957, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0164, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0346, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0241, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9845, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0143, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0276, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9858, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0164, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0059, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0330, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1398, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0161, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0759, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1259, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0758, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1093, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0224, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0390, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0653, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1576, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0477, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0436, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1087, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9954, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0574, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9907, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0029, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0470, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0778, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0559, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0340, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0748, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0722, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9795, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0359, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9887, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1482, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0238, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0893, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0540, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0262, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9659, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0632, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0054, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9697, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0666, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0896, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0307, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0278, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0499, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9276, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0612, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0297, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1170, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0370, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0404, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0104, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0121, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0628, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9409, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0335, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0495, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9877, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0612, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0139, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0401, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0861, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0406, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0158, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9867, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0250, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0245, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0644, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0325, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0606, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0562, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0892, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0657, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0697, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0854, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0489, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0562, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1358, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1086, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0564, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0016, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0661, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0801, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0260, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0261, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9628, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0955, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0194, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0440, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0521, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0090, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1127, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9974, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0231, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0351, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0646, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0275, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9576, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0128, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0364, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0563, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0334, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0157, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0186, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0532, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0443, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0396, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0720, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0291, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1230, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0084, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0690, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0835, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1013, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1033, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0700, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0726, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0676, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9884, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9990, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0780, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1177, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0259, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0518, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9530, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0889, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0072, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9961, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0405, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0953, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0498, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0920, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9571, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0017, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0961, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0229, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0310, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1346, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9944, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9341, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0667, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0889, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0107, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9787, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0006, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0252, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1105, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9818, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0619, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0702, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0716, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0778, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9920, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0355, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0462, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9937, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9711, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9609, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0609, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0324, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0382, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0211, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0958, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9990, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9791, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0449, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9865, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0246, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0672, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1345, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0204, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0648, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0319, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0966, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0249, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0634, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0514, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0997, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0681, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9859, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0244, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0116, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0541, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0812, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0281, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0431, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0502, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0274, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0530, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0612, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0700, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0256, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0130, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0073, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9695, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0636, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0376, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0466, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0063, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0518, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0396, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0512, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1046, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0912, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0319, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9940, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1068, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9902, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0856, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0017, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0873, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9388, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0755, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9910, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0358, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0250, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0761, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0539, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1306, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0274, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0257, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1363, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0364, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0568, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0163, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9622, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0895, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9782, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0436, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0500, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0553, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9651, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0122, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0619, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0709, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0706, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9955, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0350, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0243, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0370, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0875, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0409, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0228, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0273, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0005, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0211, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9879, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0774, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9860, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0616, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0508, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9831, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0996, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1241, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9976, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9680, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9732, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0812, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9672, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0377, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0985, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0551, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0095, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0229, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0228, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0053, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0560, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0323, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9819, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0426, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0175, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0960, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0081, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0426, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0449, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9984, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0890, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0510, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0083, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0463, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0615, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0818, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9404, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0712, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0483, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0603, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0373, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0135, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0492, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0465, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0740, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0124, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9658, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0272, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0244, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9608, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0487, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0114, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1075, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9837, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9957, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0708, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0689, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0301, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0926, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9643, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0377, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0035, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0481, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9853, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1099, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0516, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0729, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1047, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9647, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0341, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0390, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0592, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0178, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0420, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0017, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1146, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0065, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9743, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0145, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9917, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9973, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0980, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0457, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0440, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0649, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0660, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9644, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1124, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9871, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1136, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1540, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9818, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0681, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1349, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9630, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0442, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0730, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0036, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0207, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1444, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9755, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0745, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0549, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0241, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0874, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0475, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0851, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0078, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0317, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0784, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0691, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0927, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0146, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0475, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0965, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0532, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9999, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0125, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0292, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0493, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0644, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0202, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0661, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0207, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9546, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9947, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0410, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0152, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1040, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0665, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0177, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0433, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1159, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9682, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0411, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0087, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0344, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0127, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9651, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0403, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9951, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9680, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0004, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0003, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0782, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0385, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0149, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0364, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0832, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0180, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0303, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9516, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0723, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0705, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9826, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0319, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0977, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9795, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0342, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0718, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0163, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9980, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9980, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9982, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0356, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0147, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0829, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0391, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0528, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0876, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0424, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9632, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0273, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0351, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9852, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0736, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0123, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9793, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9789, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0846, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0413, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0343, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0688, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0294, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1019, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0327, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9835, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0803, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0475, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0566, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0235, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0428, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9421, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9655, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0116, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0087, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0531, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0296, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0165, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0116, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0058, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0753, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0418, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9741, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0566, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0494, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0268, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0457, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0855, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0240, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0684, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0325, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0143, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0338, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9839, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0999, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1023, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0634, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0821, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9929, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0072, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0287, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0908, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9438, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0150, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0566, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0026, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0368, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0388, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9809, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9663, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0175, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0114, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9855, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0260, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9951, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0910, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0212, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0320, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0692, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0442, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0825, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0076, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9972, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9369, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0184, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0398, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0779, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0322, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0635, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0436, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0650, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0944, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0419, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0646, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0616, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0467, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0878, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9804, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0535, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0344, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0549, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0036, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0281, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0831, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0082, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0226, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0775, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1067, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0092, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0270, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0251, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9651, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0121, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0253, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9762, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0226, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9863, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9994, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9783, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0363, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0210, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0175, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0035, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0400, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9894, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0722, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0998, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9497, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1096, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9988, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9711, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9598, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0122, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9896, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0561, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0123, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0213, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9946, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0214, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0622, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0863, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0612, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9869, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0350, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0728, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0237, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0872, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9792, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0241, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0042, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0480, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0567, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9691, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9740, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0352, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0009, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0559, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0555, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0506, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1394, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9593, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0666, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0239, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0181, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9942, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0454, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0555, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1171, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0040, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0430, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9871, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0070, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0662, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0156, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0326, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0646, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9697, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9884, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9729, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0058, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0071, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9877, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0374, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0767, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0130, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0342, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1434, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0007, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0601, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9935, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0210, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0175, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0256, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0644, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0703, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0811, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9669, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9396, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0696, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9867, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0431, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1163, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9870, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0884, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0729, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9973, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0401, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0673, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0147, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0213, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0132, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0836, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0103, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0451, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0459, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0704, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0331, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0566, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0168, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0298, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0541, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9990, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0380, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9955, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9799, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9927, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0219, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9928, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0858, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1374, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0352, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9842, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0530, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0360, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0568, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0611, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0153, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0286, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0284, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0346, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9783, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9595, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0278, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0425, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9894, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0284, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0369, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0426, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1116, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0259, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1341, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0302, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0373, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0410, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0408, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0193, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0523, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9887, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0194, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0296, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0814, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0845, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9945, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9855, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0840, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1069, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9946, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0955, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0017, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0302, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9997, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0334, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0349, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0681, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1334, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9481, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0458, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0456, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0573, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0913, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9958, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9582, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0097, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0032, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0621, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9886, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0723, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0252, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0493, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0047, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0061, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0731, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9758, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0352, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0252, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9427, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9724, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0535, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0568, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9722, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0230, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0247, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0540, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9341, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9946, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9993, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1128, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0622, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0146, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9815, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0759, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0303, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0042, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0194, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0626, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0009, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0821, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9648, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0168, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0024, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0309, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0263, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0846, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0247, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0112, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0259, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0835, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0419, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9639, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0518, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0346, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0427, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0267, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9773, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0203, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0648, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0471, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9876, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0991, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9872, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0339, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9839, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0720, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9633, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9679, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0425, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1048, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0492, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0712, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0220, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9792, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0971, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0240, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0497, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9998, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0289, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0242, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9589, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0247, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9842, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0285, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0753, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9719, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0333, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9960, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0452, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0145, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0157, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0664, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0186, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9720, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0250, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0337, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0231, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0181, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9907, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0019, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9701, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0184, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0421, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0808, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0921, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0442, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0059, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9806, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9877, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0168, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0122, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9681, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0477, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0140, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0330, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9889, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9989, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0063, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0582, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0479, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0184, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0109, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9706, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0138, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0336, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0144, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0501, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0522, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0385, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0103, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0651, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0316, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0073, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0174, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0155, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9472, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0172, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0319, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9446, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0380, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0693, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1576, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0763, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9887, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0381, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9932, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0574, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0006, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0177, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0958, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0584, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0236, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0302, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9701, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0759, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0192, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0417, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1380, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9899, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9627, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0064, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0513, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0121, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9963, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9687, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0050, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0518, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0753, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0620, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9960, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0215, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0447, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0257, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9833, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0240, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1074, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9918, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9613, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0129, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0861, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0278, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9864, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9351, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0116, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9853, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0724, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9818, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0082, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0420, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0178, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0309, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0477, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0628, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9783, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0119, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0411, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9979, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0551, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9545, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9661, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9522, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0250, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0036, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9580, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0539, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0689, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9816, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9531, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9688, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9927, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0175, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0315, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0554, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0801, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9704, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0200, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0632, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0541, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0275, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0407, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0587, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0373, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.8980, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1030, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9421, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0434, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0435, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0261, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0757, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9952, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9175, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0456, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0537, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0377, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0600, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9986, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0758, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0607, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9905, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1119, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1447, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0127, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9949, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0615, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1265, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0378, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0151, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0039, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0472, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9875, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9457, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0375, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0134, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0441, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0085, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9610, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0129, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9814, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0556, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0067, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9951, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0388, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0263, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0973, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9833, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0025, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0649, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0722, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9991, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0320, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9976, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0343, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0014, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0486, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9579, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0214, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0039, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0861, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0940, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0675, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0014, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0024, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9593, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0063, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0356, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0469, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0082, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9102, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0654, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0019, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9437, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9770, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9334, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9582, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9935, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9602, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0128, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0318, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0502, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9578, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9888, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9929, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0046, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0398, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9804, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9936, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0083, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0090, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0790, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0350, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0893, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0058, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0799, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9532, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0441, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0487, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0980, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9772, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0304, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0253, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9999, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0424, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9809, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0453, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0435, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1226, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0130, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0092, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9876, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0003, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0048, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0507, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0403, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9461, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0398, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0893, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1250, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9903, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0108, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0798, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0202, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9921, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0261, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0435, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0449, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9993, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0231, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0473, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0043, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9932, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0048, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9756, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9577, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0732, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9980, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0100, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9478, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0512, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0272, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0388, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0072, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9852, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0411, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0176, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0744, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0021, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0290, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0470, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0256, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9892, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0176, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9868, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0162, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0025, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9193, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0425, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9498, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0149, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0251, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0512, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0440, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0553, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9272, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0480, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0477, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9994, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9189, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9734, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9524, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0064, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9955, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9452, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9989, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0173, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0120, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0331, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0391, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0659, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0182, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0368, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0065, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9963, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0015, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0735, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9931, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9943, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9554, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9721, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9573, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0491, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0063, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1090, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0033, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0062, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0315, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0845, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0669, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0360, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0049, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0321, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0275, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0305, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0626, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9634, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9756, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9477, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9462, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0071, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0031, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0034, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9584, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9729, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0414, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9781, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0413, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0256, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9918, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9673, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9552, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0220, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9583, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9832, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9383, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0086, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0302, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0312, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0354, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0668, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0860, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0556, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9987, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9698, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9942, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0089, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0562, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9286, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0099, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0026, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0019, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0429, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9871, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0393, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0050, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9702, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9830, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9844, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0242, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9901, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9863, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9641, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0026, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0079, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0109, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0260, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9994, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9723, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0499, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0003, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0243, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0812, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9921, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9192, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9822, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0123, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0461, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9725, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9081, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0597, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9496, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0092, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0652, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0190, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0260, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9705, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0298, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0146, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0223, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9901, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0428, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0375, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9898, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0041, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9556, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9851, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0141, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0519, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9908, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9511, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0806, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9750, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9628, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9648, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0901, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0111, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9920, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0032, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0405, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0521, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0613, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0754, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0442, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9439, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0842, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0318, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0134, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9956, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9818, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0008, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0107, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9797, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9548, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0533, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0007, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0044, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0587, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0997, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0045, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0111, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0458, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0140, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0219, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0267, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9888, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0326, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1068, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9795, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0352, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0387, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0344, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9374, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0390, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9854, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0811, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9812, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0370, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9776, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0628, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9725, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9167, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0016, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0374, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0711, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0413, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0587, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9835, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0143, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9911, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0529, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0041, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0004, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9538, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0380, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.8806, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0059, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9677, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0483, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0344, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0135, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9765, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9962, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0155, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0500, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0507, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0120, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9821, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0035, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1125, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0111, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0586, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0972, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0552, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0489, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9946, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9212, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9380, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0237, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0350, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0086, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9762, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0081, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9898, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0255, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9183, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0484, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9951, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0223, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0416, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0729, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0383, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0908, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0471, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0277, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0444, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0055, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0715, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9689, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0081, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0236, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9701, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.1064, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0554, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0128, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9833, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0979, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0032, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9971, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9825, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9933, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0349, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9812, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0234, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9917, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0820, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9190, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0852, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9675, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0302, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0195, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0389, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(1.0384, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9375, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0449, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0096, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9923, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9280, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0941, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0377, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0731, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0263, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0478, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0531, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9860, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0138, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0397, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0461, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0319, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9966, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9878, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9493, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0165, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0173, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0237, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0519, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0162, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9531, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9936, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0058, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9797, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9928, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0272, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9514, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0530, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0723, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0755, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0423, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0341, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0348, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0158, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0209, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9606, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9882, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(1.0184, grad_fn=<NllLossBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "tensor(0.9405, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/333 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (validation):   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (test):   0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"metric\": \"mean\" (\"standard deviation\")\n",
      "dcg: 106.2841 (23.82761)\n",
      "dcg@03: 18.7750 (9.29225)\n",
      "dcg@05: 22.7144 (11.00661)\n",
      "dcg@10: 28.6539 (12.50528)\n",
      "dcg@20: 36.3295 (13.04381)\n",
      "ndcg: 0.8203 (0.05849)\n",
      "ndcg@03: 0.6379 (0.27880)\n",
      "ndcg@05: 0.5840 (0.23676)\n",
      "ndcg@10: 0.5415 (0.18077)\n",
      "ndcg@20: 0.5269 (0.13510)\n",
      "precision@01: 0.7265 (0.44576)\n",
      "precision@03: 0.6439 (0.33962)\n",
      "precision@05: 0.5299 (0.30418)\n",
      "precision@10: 0.3846 (0.22289)\n",
      "precision@20: 0.2850 (0.14025)\n",
      "recall@01: 0.0338 (0.02987)\n",
      "recall@03: 0.0847 (0.05930)\n",
      "recall@05: 0.1131 (0.08145)\n",
      "recall@10: 0.1588 (0.10085)\n",
      "recall@20: 0.2337 (0.11130)\n",
      "relevant rank: 78.8711 (66.07048)\n",
      "relevant rank per query: 2029.7521 (1102.90310)\n"
     ]
    }
   ],
   "source": [
    "seed(42)\n",
    "params_clf = Namespace(epochs=13, \n",
    "                    lr=1e-3,\n",
    "                    batch_size=256,\n",
    "                    metrics={\"ndcg\", \"precision@05\", \"recall@05\"})\n",
    "\n",
    "pointwise_classification_model = NeuralModule(5)\n",
    "create_results(pointwise_classification_model,\n",
    "               train_pointwise,\n",
    "               partial(clf_pred, net=pointwise_classification_model),\n",
    "               \"./pointwise_classification.json\", \"clf\", params_clf)\n",
    "\n",
    "torch.save(pointwise_classification_model.state_dict(), \"./pointwise_clf_wt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ab42dfe7a4ffdce839f7f3990147830",
     "grade": true,
     "grade_id": "cell-ccb9cdbf2280bcff",
     "locked": false,
     "points": 30,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8123d91619096913bd0809c27781857",
     "grade": true,
     "grade_id": "cell-780585f47729739e",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert os.path.exists(\"./pointwise_regression.json\")\n",
    "assert os.path.exists(\"./pointwise_classification.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed8a82c097df5799c15c9000475ad11e",
     "grade": false,
     "grade_id": "cell-e48bb26c37eacea9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Section 3: Pairwise LTR (60 points) <a class=\"anchor\" id=\"pairwiseLTR\"></a>\n",
    "\n",
    "[Back to TOC](#top)\n",
    "\n",
    "In this section,  you will learn and implement RankNet, a  pairwise learning to rank algorithm.\n",
    "\n",
    "For a given query, consider two documents $D_i$ and $D_j$ with two different ground truth relevance  labels,  with  feature  vectors $x_i$ and $x_j$ respectively.   The  RankNet  model,  just  like  the pointwise model, uses $f$ to predict scores i.e $s_i=f(x_i)$ and $s_j=f(x_j)$, but uses a different loss during  training. $D_i \\triangleright D_j$ denotes  the  event  that $D_i$ should  be  ranked  higher  than $D_j$.   The  two outputs $s_i$ and $s_j$ are mapped to a learned probability that $D_i \\triangleright D_j$: \n",
    "\n",
    "\n",
    "$$        P_{ij} = \\frac{1}{1 + e^{-\\sigma(s_i - s_j)}} $$\n",
    "  \n",
    "where $\\sigma$ is a parameter that determines the shape of the sigmoid. The loss of the RankNet model is the cross entropy cost function:\n",
    "\n",
    "$$        C = - \\bar{P}_{ij} \\log P_{ij} - (1-\\bar{P}_{ij}) \\log (1 - P_{ij}) $$\n",
    "\n",
    "As the name suggests, in the pairwise approach to LTR, we optimize a loss $l$ over pairs of documents. Let $S_{ij} \\in \\{0, \\pm1 \\}$ be equal to $1$ if the relevance of document $i$ is greater than document $j$; $-1$ if document $j$ is more relevant than document $i$; and 0 if they have the same relevance. This gives us $\\bar{P}_{ij} = \\frac{1}{2} (1 + S_{ij})$ so that $\\bar{P}_{ij} = 1$ if $D_i \\triangleright D_j$; $\\bar{P}_{ij} = 0$ if $D_j \\triangleright D_i$; and finally $\\bar{P}_{ij} = \\frac{1}{2}$ if the relevance is identical. This gives us:\n",
    "\n",
    "$$        C = \\frac{1}{2}(1- S_{ij})\\sigma(s_i - s_j) + \\log(1+ e^{-\\sigma(s_i - s_j)}) $$\n",
    "\n",
    "Now, consider a single query for which $n$ documents have been returned. Let the output scores of the ranker be $s_j$ ; $j=\\{1, \\dots, n \\}$, the model parameters be $w_k \\in \\mathbb{R}^W$, and let the set of pairs of document indices used for training be $\\mathcal{P}$. Then, the total cost is $C_T = \\sum_{i,j \\in \\mathcal{P}} C(s_i; s_j)$. \n",
    "\n",
    "\n",
    "\n",
    "- Implement RankNet. You should construct training samples by creating all possible pairs of documents for a given query and optimizing the loss above. Use the following parameters:\n",
    "  - Layers: $501 (input) \\rightarrow 256 \\rightarrow 1$, where each layer is a linear layer (`nn.Linear`) with a ReLu activation function (`nn.ReLu`) in between the layers. Use the default weight initialization scheme. (Hint: use `nn.Sequential` for a one-line forward function!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e80a1fc2830a7bfe3be62c3bbf1df5b7",
     "grade": false,
     "grade_id": "cell-5359ecd282448c2a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For the pairwise loss, we need to have a structured **dataloader** which detects the documents associated with a specific query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e50a3b3ef0bf4fba2f792073ebb8443",
     "grade": false,
     "grade_id": "cell-0009b5254fc5f2ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 273 has 35 query-document pairs\n",
      "Shape of features for Query 273: torch.Size([35, 501])\n"
     ]
    }
   ],
   "source": [
    "class QueryGroupedLTRData(Dataset):\n",
    "    def __init__(self, data, split):\n",
    "        self.split = {\n",
    "            \"train\": data.train,\n",
    "            \"validation\": data.validation,\n",
    "            \"test\": data.test\n",
    "        }.get(split)\n",
    "        assert self.split is not None, \"Invalid split!\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.split.num_queries()\n",
    "\n",
    "    def __getitem__(self, q_i):\n",
    "        feature = torch.FloatTensor(self.split.query_feat(q_i))\n",
    "        labels = torch.FloatTensor(self.split.query_labels(q_i))\n",
    "        return q_i, feature, labels\n",
    "\n",
    "# the return types are different from what pytorch expects, \n",
    "# so we will define a custom collate function which takes in\n",
    "# a batch and returns tensors (qids, features, labels) \n",
    "def qg_collate_fn(batch):\n",
    "    \n",
    "    qids = []\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for (q, f, l) in batch:\n",
    "        qids.append(q)\n",
    "        features.append(f)\n",
    "        labels.append(l)\n",
    "    \n",
    "    return qids, features, labels\n",
    "    \n",
    "    \n",
    "## example - NOTE the collate_fn argument!\n",
    "train_dl = DataLoader(QueryGroupedLTRData(data, \"train\"), batch_size=1, shuffle=True, collate_fn=qg_collate_fn)\n",
    "# this is how you would use it to quickly iterate over the train/val/test sets \n",
    "for (qids, x, y) in train_dl:\n",
    "    # different from the previous data loader, qids, x and y aren't tensors, but lists!\n",
    "    for q_i, features_i, labels_i in zip(qids, x, y):\n",
    "        print(f\"Query {q_i} has {len(features_i)} query-document pairs\")\n",
    "        print(f\"Shape of features for Query {q_i}: {features_i.size()}\")\n",
    "        break\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fd7eb669f10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataLoader(QueryGroupedLTRData(data, \"train\"), batch_size=1, shuffle=True, collate_fn=qg_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c719c1aca6aa05893f903f78d75ba94",
     "grade": false,
     "grade_id": "cell-acdb1bfcd2ec582e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Implementation (25 points):**\n",
    "First, implement the pairwaise loss, described above.\n",
    "\n",
    "**Rubric:**\n",
    " - Each ordering <i,j> combination is considered: 10 points\n",
    " - Proper application of the formula: 10 points\n",
    " - Mean loss: 5 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3dcefb2b21b4524aa03cdf22382934ba",
     "grade": false,
     "grade_id": "cell-3a612aeb9e982639",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (25 points)\n",
    "def pairwise_loss(scores, labels):\n",
    "    \"\"\"\n",
    "    Compute and return the pairwise loss *for a single query*. To compute this, compute the loss for each \n",
    "    ordering in a query, and then return the mean. Use sigma=1.\n",
    "    \n",
    "    For a query, consider all possible ways of comparing 2 document-query pairs.\n",
    "    \n",
    "    Hint: See the next cell for an example which should make it clear how the inputs look like\n",
    "    \n",
    "    scores: tensor of size [N, 1] (the output of a neural network), where N = length of <query, document> pairs\n",
    "    labels: tensor of size [N], contains the relevance labels \n",
    "    \n",
    "    \"\"\"\n",
    "    # if there's only one rating\n",
    "    if labels.size(0) < 2:\n",
    "        return None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Helper function for Sij ∈ {−1,0,1}\n",
    "    def relevance(l1, l2):\n",
    "        if l1 > l2:\n",
    "            return 1\n",
    "        elif l1 < l2:\n",
    "            return -1\n",
    "        \n",
    "        return 0\n",
    "    \n",
    "    sigma = 1\n",
    "    loss = []\n",
    "    \n",
    "    # Note that the order of combinations does matter\n",
    "    \n",
    "    for i in range(len(scores)):\n",
    "        for j in range(len(scores)):\n",
    "            \n",
    "            if i == j:\n",
    "                continue\n",
    "            \n",
    "            # Divide formula in two parts due to readability\n",
    "            C1 = 0.5 * (1 - relevance(labels[i], labels[j])) * sigma * (scores[i] - scores[j])\n",
    "            C2 = torch.log(1 + torch.exp(-sigma*(scores[i]-scores[j])))\n",
    "            \n",
    "            # Append loss to list\n",
    "            loss.append(C1 + C2)\n",
    "            \n",
    "    # return average loss\n",
    "    return torch.mean(torch.stack(loss), dim=0)\n",
    "\n",
    "# Unsure about this; are we supposed to use labels like this? How do we interpret relevance? \n",
    "# Increasing or decreasing order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "234a4669f7c7e14949006be676cabb90",
     "grade": false,
     "grade_id": "cell-01f6e909bc892bc8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6869)\n",
      "tensor(0.2014)\n"
     ]
    }
   ],
   "source": [
    "# Let's say we have 2 queries, the first one with 5 <document, query> pairs \n",
    "#    and the second one with 2 <document, query> pairs. The two variables can\n",
    "#    look something like this (note the shape, not the values):\n",
    "\n",
    "scores_1 = torch.FloatTensor([0.2, 2.3, 4.5, 0.2, 1.0])\n",
    "labels_1 = torch.FloatTensor([1, 2, 3, 0, 4])\n",
    "\n",
    "\n",
    "scores_2 = torch.FloatTensor([3.2, 1.7])\n",
    "labels_2 = torch.FloatTensor([3, 1])\n",
    "\n",
    "print(pairwise_loss(scores_1, labels_1))\n",
    "print(pairwise_loss(scores_2, labels_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "618bd72120cdd1baae3f22733f124d6c",
     "grade": true,
     "grade_id": "cell-5f706c38e99721df",
     "locked": false,
     "points": 25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b63a41669c7a768f5420d43968a53212",
     "grade": false,
     "grade_id": "cell-45f14561e4843320",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Implementation (35 points):**\n",
    "Now implement the wrapper for the pairwise LTR.\n",
    "\n",
    "**Rubric:**\n",
    " - Network is trained for specified epochs, and iterates over the entire dataset\n",
    " - and (train) data is shuffled : 10 points\n",
    " - Loss calculation: 10 points\n",
    " - Evaluation on the validation set: 5 points\n",
    " - Training (e.g optimizer, zero_grad, backward): 10 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31ad65b3cbd923af54ff56f804bbc93c",
     "grade": false,
     "grade_id": "cell-a85c38ca94031203",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (35 points)\n",
    "def train_pairwise(net, params):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function should train the given network using the pairwise loss\n",
    "    \n",
    "    Returns: a dictionary containing: \"metrics_val\" (a list of dictionaries) and \n",
    "             \"metrics_train\" (a list of dictionaries). \n",
    "             \n",
    "             \"metrics_val\" should contain metrics (the metrics in params.metrics) computed\n",
    "             after each epoch on the validation set (metrics_train is similar). \n",
    "             You can use this to debug your models\n",
    "    \n",
    "    Note: Do not change the function definition! \n",
    "    Note: You can assume params.batch_size will always be equal to 1\n",
    "    \n",
    "    Hint: Consider the case when the loss function returns 'None'\n",
    "    \n",
    "    net: the neural network to be trained\n",
    "    \n",
    "    params: params is an object which contains config used in training \n",
    "        (eg. params.epochs - the number of epochs to train). \n",
    "        For a full list of these params, see the next cell. \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    val_metrics_epoch = []\n",
    "    train_metrics_epoch = []\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    epochs = params.epochs\n",
    "    lr = params.lr\n",
    "    batch_size = params.batch_size\n",
    "    metrics = params.metrics\n",
    "    \n",
    "    DataLoader(QueryGroupedLTRData(data, \"train\"), batch_size=batch_size, shuffle=True, collate_fn=qg_collate_fn)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch} lr:{lr}\")\n",
    "        for (qids, x, y) in tqdm(train_dl):\n",
    "            for q_i, features_i, labels_i in zip(qids, x, y):\n",
    "                pred = net(features_i)\n",
    "                loss = pairwise_loss(pred, labels_i)\n",
    "                \n",
    "                # returning None means that there is only one rating\n",
    "                if loss.item() == None:\n",
    "                    continue\n",
    "                    \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        m_trn = evaluate_model(net.eval(), \"train\", batch_size=batch_size)\n",
    "        train_metrics_epoch.append({m: m_trn[m] for m in metrics})\n",
    "        \n",
    "        m_val = evaluate_model(net.eval(), \"validation\", batch_size=batch_size)\n",
    "        val_metrics_epoch.append({m: m_val[m] for m in metrics})\n",
    "        \n",
    "    return {\n",
    "        \"metrics_val\": val_metrics_epoch,\n",
    "        \"metrics_train\": train_metrics_epoch\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 lr:0.001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9301e121c8d64c41a4758bd68fe8f587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2735 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/85227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-39af9be8828d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpairwise_params_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNamespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"ndcg\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpairwise_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairwise_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairwise_params_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m pairwise_test, pairwise_q = evaluate_model(pairwise_net,\n\u001b[1;32m      5\u001b[0m                                          \"test\", print_results=True, q_level=True)\n",
      "\u001b[0;32m<ipython-input-84-8aee2152c17c>\u001b[0m in \u001b[0;36mtrain_pairwise\u001b[0;34m(net, params)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mm_trn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mtrain_metrics_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm_trn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-6fec0b271377>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(pred_fn, split, batch_size, print_results, q_level)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     }.get(split)   \n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/IR1/hw2/evaluate.py\u001b[0m in \u001b[0;36mevaluate2\u001b[0;34m(all_scores, all_labels, print_results, q_level)\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mq_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m       \u001b[0madd_to_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_labels_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mprint_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/IR1/hw2/evaluate.py\u001b[0m in \u001b[0;36mevaluate_labels_scores\u001b[0;34m(labels, scores)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_labels_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mn_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   random_i = np.random.permutation(\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "pairwise_params_test = Namespace(epochs=1, lr=1e-3, batch_size=1, metrics={\"ndcg\"})\n",
    "pairwise_net = NeuralModule(1)\n",
    "train_pairwise(pairwise_net, pairwise_params_test)\n",
    "pairwise_test, pairwise_q = evaluate_model(pairwise_net,\n",
    "                                         \"test\", print_results=True, q_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 lr:0.001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2c65b7af464cf1987937795cdf916d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2735 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval (train):   0%|          | 0/85227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-39af9be8828d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpairwise_params_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNamespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"ndcg\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpairwise_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairwise_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairwise_params_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m pairwise_test, pairwise_q = evaluate_model(pairwise_net,\n\u001b[1;32m      5\u001b[0m                                          \"test\", print_results=True, q_level=True)\n",
      "\u001b[0;32m<ipython-input-55-8aee2152c17c>\u001b[0m in \u001b[0;36mtrain_pairwise\u001b[0;34m(net, params)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mm_trn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mtrain_metrics_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm_trn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-6fec0b271377>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(pred_fn, split, batch_size, print_results, q_level)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     }.get(split)   \n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/IR1/hw2/evaluate.py\u001b[0m in \u001b[0;36mevaluate2\u001b[0;34m(all_scores, all_labels, print_results, q_level)\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mq_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m       \u001b[0madd_to_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_labels_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mprint_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/IR1/hw2/evaluate.py\u001b[0m in \u001b[0;36mevaluate_labels_scores\u001b[0;34m(labels, scores)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_labels_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mn_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   random_i = np.random.permutation(\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "pairwise_params_test = Namespace(epochs=1, lr=1e-3, batch_size=1, metrics={\"ndcg\"})\n",
    "pairwise_net = NeuralModule(1)\n",
    "train_pairwise(pairwise_net, pairwise_params_test)\n",
    "pairwise_test, pairwise_q = evaluate_model(pairwise_net,\n",
    "                                         \"test\", print_results=True, q_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4b97202b1befddb4af2ec7851c5d174",
     "grade": false,
     "grade_id": "cell-19ec0cf692c86b75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pairwise_params_test = Namespace(epochs=1, lr=1e-3, batch_size=1, metrics={\"ndcg\"})\n",
    "## uncomment to test your code\n",
    "# pairwise_net = NeuralModule(1)\n",
    "# train_pairwise(pairwise_net, pairwise_params_test)\n",
    "# pairwise_test, pairwise_q = evaluate_model(pairwise_net,\n",
    "#                                          \"test\", print_results=True, q_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52558867a0a7f79d6c42ceab4f26a132",
     "grade": true,
     "grade_id": "cell-34178113ea5e9331",
     "locked": false,
     "points": 35,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pairwise_params_test = Namespace(epochs=2, lr=1e-3, batch_size=1, metrics={\"ndcg\"})\n",
    "pairwise_net = NeuralModule(1)\n",
    "train_pairwise(pairwise_net, pairwise_params_test)\n",
    "pairwise_test, pairwise_q = evaluate_model(pairwise_net,\n",
    "                                         \"test\", print_results=True, q_level=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3867bfe2e108bffb3ae69f5ddfd68834",
     "grade": false,
     "grade_id": "cell-3a95bb01f72fc76c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Section 4: Pairwise: Speed-up RankNet (70 points) <a class=\"anchor\" id=\"SpairwiseLTR\"></a>\n",
    "\n",
    "[Back to TOC](#top)\n",
    "\n",
    "To speed up training of the previous model, we can consider a sped up version of the model, where instead of `.backward` on the loss, we use `torch.backward(lambda_i)`. \n",
    "\n",
    "The derivative of the total cost $C_T$ with respect to the model parameters $w_k$ is:\n",
    "\n",
    "$$        \\frac{\\partial C_T}{\\partial w_k} = \\sum_{(i,j) \\in \\mathcal{P}} \\frac{\\partial C(s_i, s_j)}{\\partial s_i} \\frac{\\partial s_i}{\\partial w_k} + \\frac{\\partial C(s_i, s_j)}{\\partial s_j} \\frac{\\partial s_j}{\\partial w_k} $$\n",
    "\n",
    "We can rewrite this sum by considering the set of indices $j$ , for which $\\{i,j\\}$ is a valid pair, denoted by $\\mathcal{P}_i$, and the set of document indices $\\mathcal{D}$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial C_T}{\\partial w_k} = \\sum_{i \\in \\mathcal{D}}\n",
    "\\frac{\\partial s_i}{\\partial w_k} \\sum_{j \\in \\mathcal{P}_i} \n",
    "\\frac{\\partial C(s_i, s_j)}{\\partial s_i} \n",
    "$$\n",
    "\n",
    "This sped of version of the algorithm first computes scores $s_i$ for all the documents. Then for each $j= 1, \\dots, n$, compute:\n",
    "\n",
    "$$\n",
    "\\lambda_{ij} = \\frac{\\partial C(s_i, s_j)}{\\partial s_i} = \\sigma \\bigg( \\frac{1}{2}(1 - S_{ij}) -  \\frac{1}{1 + e^{\\sigma(s_i -s_j))}} \\bigg) \\\\\n",
    "\\lambda_i = \\sum_{j \\in \\mathcal{P}_i} \\frac{\\partial C(s_i, s_j)}{\\partial s_i} = \\sum_{j \\in \\mathcal{P}_i} \\lambda_{ij}\n",
    "$$\n",
    "\n",
    "That gives us:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial C_T}{\\partial w_k} = \\sum_{i \\in \\mathcal{D}}\n",
    "\\frac{\\partial s_i}{\\partial w_k} \\lambda_i\n",
    "$$\n",
    "\n",
    "This can be directly optimized in pytorch using: `torch.autograd.backward(scores, lambda_i)` \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c88f76d295dd1dc2778cd2413b4c58e8",
     "grade": false,
     "grade_id": "cell-2a9b7b682a011642",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Implementation (20 points):**\n",
    "Implement the sped-up version of pairwise loss, described above.\n",
    "\n",
    "**Rubric:**\n",
    " - Each ordering <i,j> combination is considered: 10 points\n",
    " - Proper application of the formula: 10 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cea38cdd68cb70d08e33827bffc53a8",
     "grade": false,
     "grade_id": "cell-ba7f8d8631e3f1d6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (20 points)\n",
    "def compute_lambda_i(scores, labels):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute \\lambda_i (defined in the previous cell). (assume sigma=1.)\n",
    "    \n",
    "    scores: tensor of size [N, 1] (the output of a neural network), where N = length of <query, document> pairs\n",
    "    labels: tensor of size [N], contains the relevance labels \n",
    "    \n",
    "    return: \\lambda_i, a tensor of shape: [N, 1]\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    import math\n",
    "    sigma = 1\n",
    "    \n",
    "    # Calculates the different scores between document i and document j \n",
    "    scoring_diff = scores.view(scores.size()[0],1) - scores.view(1,scores.size()[0])\n",
    "    \n",
    "    # Calculates the indicated preference between document i and document j \n",
    "    preference_diff = torch.sign(labels.view(labels.size()[0],1) - labels.view(1, labels.size()[0]))\n",
    "    \n",
    "    lambda_ij = sigma * (1/2*(1-preference_diff)-(1/(1+np.exp(sigma*scoring_diff))))\n",
    "    \n",
    "    lambda_i = torch.sum(lambda_ij, 1) \n",
    "    \n",
    "    return lambda_i.view(len(lambda_i), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c4533f39d3dfbefdd4b56c61316eac8",
     "grade": true,
     "grade_id": "cell-756179237da34c57",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0675],\n",
      "        [ 0.6674],\n",
      "        [ 0.8442],\n",
      "        [ 0.9325],\n",
      "        [-2.3766]])\n",
      "tensor([[-0.1824],\n",
      "        [ 0.1824]])\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "scores_1 = torch.FloatTensor([0.2, 2.3, 4.5, 0.2, 1.0])\n",
    "labels_1 = torch.FloatTensor([1, 2, 3, 0, 4])\n",
    "\n",
    "\n",
    "scores_2 = torch.FloatTensor([3.2, 1.7])\n",
    "labels_2 = torch.FloatTensor([3, 1])\n",
    "\n",
    "\n",
    "print(compute_lambda_i(scores_1, labels_1))\n",
    "print(compute_lambda_i(scores_2, labels_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00482b2615dc28ead4c745a705e5fafb",
     "grade": false,
     "grade_id": "cell-ed55c62fbba08923",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Implementation (50 points):**\n",
    "Using the sped-up loss function `compute_lambda_i`, implement the spedup wrapper for pairwise training.\n",
    "\n",
    "**Rubric:**\n",
    " - Network is trained for specified epochs, and iterates over the entire dataset and (train) data is shuffled : 10 points\n",
    " - Loss calculation: 10 points\n",
    " - Evaluation on the validation set: 5 points\n",
    " - Training (e.g optimizer, zero_grad, backward): 10 points\n",
    " - Performance as expected: 15 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "14e4da9878b2e0a3603437b29a66a07c",
     "grade": false,
     "grade_id": "cell-ddfeb927c2f4a31c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (50 points)\n",
    "def train_pairwise_spedup(net, params):\n",
    "    \"\"\"\n",
    "    This function should train the given network using the sped up pairwise loss\n",
    "    \n",
    "    \n",
    "    Note: Do not change the function definition! \n",
    "    Note: You can assume params.batch_size will always be equal to 1\n",
    "    \n",
    "    \n",
    "    net: the neural network to be trained\n",
    "    \n",
    "    params: params is an object which contains config used in training \n",
    "        (eg. params.epochs - the number of epochs to train). \n",
    "        For a full list of these params, see the next cell. \n",
    "    \n",
    "    Returns: a dictionary containing: \"metrics_val\" (a list of dictionaries) and \n",
    "             \"metrics_train\" (a list of dictionaries). \n",
    "             \n",
    "             \"metrics_val\" should contain metrics (the metrics in params.metrics) computed\n",
    "             after each epoch on the validation set (metrics_train is similar). \n",
    "             You can use this to debug your models\n",
    "    \"\"\"\n",
    "    \n",
    "    val_metrics_epoch = []\n",
    "    train_metrics_epoch = []\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    epochs = params.epochs\n",
    "    lr = params.lr\n",
    "    metrics = params.metrics\n",
    "    \n",
    "    DataLoader(QueryGroupedLTRData(data, \"train\"), batch_size=1, shuffle=True, collate_fn=qg_collate_fn)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch} lr:{lr}\")\n",
    "        for (qids, x, y) in tqdm(train_dl):\n",
    "            for q_i, features_i, labels_i in zip(qids, x, y):\n",
    "                pred = net(features_i)\n",
    "                loss = pairwise_loss(pred, labels_i)\n",
    "                \n",
    "                # returning None means that there is only one rating\n",
    "                if loss.item() == None:\n",
    "                    continue\n",
    "                    \n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Dit klopt niet -> vraag\n",
    "                # Also needs to be compute lambda i first\n",
    "                \n",
    "                torch.autograd.backward(pred, compute_lambda_i(pred, labels_i))\n",
    "                \n",
    "                optimizer.step()\n",
    "\n",
    "        m_trn = evaluate_model(net.eval(), \"train\", batch_size=1)\n",
    "        train_metrics_epoch.append({m: m_trn[m] for m in metrics})\n",
    "        \n",
    "        m_val = evaluate_model(net.eval(), \"validation\", batch_size=1)\n",
    "        val_metrics_epoch.append({m: m_val[m] for m in metrics})\n",
    "        \n",
    "    \n",
    "    \n",
    "    return {\n",
    "        \"metrics_val\": val_metrics_epoch,\n",
    "        \"metrics_train\": train_metrics_epoch\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb9b27b6ec712d8d1146751bc150791e",
     "grade": false,
     "grade_id": "cell-f80dc2eae24968ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# uncomment to test your code\n",
    "# pairwise_spedup_params_test = Namespace(epochs=1, lr=1e-3, batch_size=1, metrics={\"ndcg@10\",\"ndcg\"})\n",
    "# pairwise_net_spedup = NeuralModule(1)\n",
    "# train_pairwise_spedup(pairwise_net_spedup, pairwise_spedup_params_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c173b7020a1122f7218bbf37ee370884",
     "grade": false,
     "grade_id": "cell-20aa326063f673c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The next cell creates the results file you will have to submit. *Note that the next cell trains and evaluates only the sped-up version - this is intentional!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77211db554a4bb37582d7c61c7170243",
     "grade": false,
     "grade_id": "cell-32660e207ce6d16a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n",
      "Epoch 0 lr:0.001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a594b57f71d346d1971dfb52dcd75e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2735 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-eb9dd35bee57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpairwise_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m create_results(pairwise_model, \n\u001b[0m\u001b[1;32m      9\u001b[0m                \u001b[0mtrain_pairwise_spedup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                \u001b[0mpairwise_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-4590cbe3bc73>\u001b[0m in \u001b[0;36mcreate_results\u001b[0;34m(net, train_fn, prediction_fn, results_file, *train_params)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_qq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-60ae097a4699>\u001b[0m in \u001b[0;36mtrain_pairwise_spedup\u001b[0;34m(net, params)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;31m# Also needs to be compute lambda i first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_lambda_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-f5246f5b0a35>\u001b[0m in \u001b[0;36mcompute_lambda_i\u001b[0;34m(scores, labels)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mpreference_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlambda_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpreference_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscoring_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mlambda_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_ij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/torchenv/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "seed(42)\n",
    "params = Namespace(epochs=8, \n",
    "                    lr=1e-3,\n",
    "                    batch_size=1,\n",
    "                    metrics={\"ndcg\", \"precision@05\", \"recall@05\"})\n",
    "pairwise_model = NeuralModule(1)\n",
    "\n",
    "create_results(pairwise_model, \n",
    "               train_pairwise_spedup, \n",
    "               pairwise_model,\n",
    "               \"./pairwise.json\",\n",
    "               params)\n",
    "# persist model\n",
    "torch.save(pairwise_model.state_dict(), \"./pairwise_wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(42)\n",
    "params = Namespace(epochs=8, \n",
    "                    lr=1e-3,\n",
    "                    batch_size=1,\n",
    "                    metrics={\"ndcg\", \"precision@05\", \"recall@05\"})\n",
    "pairwise_model = NeuralModule(1)\n",
    "\n",
    "create_results(pairwise_model, \n",
    "               train_pairwise_spedup, \n",
    "               pairwise_model,\n",
    "               \"./pairwise.json\",\n",
    "               params)\n",
    "# persist model\n",
    "torch.save(pairwise_model.state_dict(), \"./pairwise_wt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3cc6f1a702be838b6e26733b089d5bda",
     "grade": true,
     "grade_id": "cell-8aad7ba1f8c6c23c",
     "locked": false,
     "points": 35,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b46d1ebc1676bc1dbce629b0a978326",
     "grade": true,
     "grade_id": "cell-3dc8ee835753e5aa",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert os.path.exists(\"./pairwise.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60ad8126d68fcf4814988ad22c335c2a",
     "grade": false,
     "grade_id": "cell-14e048f55b2e6aea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##  Section 5: Listwise LTR (80 points) <a class=\"anchor\" id=\"listwiseLTR\"></a>\n",
    "\n",
    "[Back to TOC](#top)\n",
    "\n",
    "In this section, you will implement LambdaRank, a listwise approach to LTR. Consider the computation of $\\lambda$ for sped-up RankNet (that you've already implemented). $\\lambda$ here amounts to the 'force' on a document given its neighbours in the ranked list. The design of $\\lambda$ in LambdaRank is similar to RankNet, but is scaled by DCG gain from swapping the two documents in question. Let's suppose that the corresponding ranks of doucment $D_i$ and $D_j$ are $r_i$ and $r_j$ respectively. Given a ranking measure $IRM$, such as $NDCG$ or $ERR$, the lambda function in LambdaRank is defined as:\n",
    "\n",
    "\n",
    "$$        \\frac{\\partial C}{\\partial s_i} = \\sum_{j \\in D} \\lambda_{ij} \\cdot |\\bigtriangleup IRM (i,j)| $$\n",
    "\n",
    "Where $|\\bigtriangleup IRM(i,j)|$ is the absolute difference in $IRM$ after swapping the rank positions $r_i$ and $r_j$ while leaving everything else unchanged ($| \\cdot |$ denotes the absolute value). Note that we do not backpropogate $|\\bigtriangleup IRM|$, it is treated as a constant that scales the gradients. In this assignment we will use $|\\bigtriangleup NDCG|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0caedecf5dcfd8b561a99f58ea756abd",
     "grade": false,
     "grade_id": "cell-351c194e6797d0a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Implementation (30 points):**\n",
    "Implement the listwise loss.\n",
    "\n",
    "**Rubric:**\n",
    " - Each ordering <i,j> combination is considered: 10 points\n",
    " - Computing $|\\bigtriangleup NDCG|$: 10 points \n",
    " - Proper application of the formula: 10 points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0ba4266e951c80236d3dc6f0e0c32a5",
     "grade": false,
     "grade_id": "cell-48f6a2a1c4a529b6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (30 points)\n",
    "def listwise_loss(scores, labels):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the LambdaRank loss. (assume sigma=1.)\n",
    "    \n",
    "    scores: tensor of size [N, 1] (the output of a neural network), where N = length of <query, document> pairs\n",
    "    labels: tensor of size [N], contains the relevance labels \n",
    "    \n",
    "    returns: a tensor of size [N, 1]\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28f708cd49db29860a2774a320685d18",
     "grade": false,
     "grade_id": "cell-7ffca014e68d2c32",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "scores_1 = torch.FloatTensor([0.2, 2.3, 4.5, 0.2, 1.0])\n",
    "labels_1 = torch.FloatTensor([1, 2, 3, 0, 4])\n",
    "\n",
    "\n",
    "scores_2 = torch.FloatTensor([3.2, 1.7])\n",
    "labels_2 = torch.FloatTensor([3, 1])\n",
    "\n",
    "\n",
    "print(listwise_loss(scores_1, labels_1))\n",
    "\n",
    "\n",
    "\n",
    "print(listwise_loss(scores_2, labels_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3c154e9791120fcb899928865f40d30",
     "grade": true,
     "grade_id": "cell-fadab94bb19ea7ee",
     "locked": false,
     "points": 30,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "48df2b36472c6f03f84a293fea5d3602",
     "grade": false,
     "grade_id": "cell-7dec2c279f77b272",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### **Implementation (50 points):**\n",
    "And use the loss function above to train a listwise LTR.\n",
    "\n",
    "**Rubric:**\n",
    " - Network is trained for specified epochs, and iterates over the entire dataset and (train) data is shuffled : 10 points\n",
    " - Loss calculation: 10 points\n",
    " - Evaluation on the validation set: 5 points\n",
    " - Training (e.g optimizer, zero_grad, backward): 10 points\n",
    " - Performance as expected: 15 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "786e51ea263d0ea82a5ec251344f7d0e",
     "grade": false,
     "grade_id": "cell-34c4d0bdbb753580",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (50 points)\n",
    "\n",
    "def train_listwise(net, params):\n",
    "    \"\"\"\n",
    "    This function should train the given network using the listwise (LambdaRank) loss\n",
    "    \n",
    "    Note: Do not change the function definition! \n",
    "    Note: You can assume params.batch_size will always be equal to 1\n",
    "    \n",
    "    \n",
    "    net: the neural network to be trained\n",
    "    \n",
    "    params: params is an object which contains config used in training \n",
    "        (eg. params.epochs - the number of epochs to train). \n",
    "        For a full list of these params, see the next cell. \n",
    "        \n",
    "    Returns: a dictionary containing: \"metrics_val\" (a list of dictionaries) and \n",
    "             \"metrics_train\" (a list of dictionaries). \n",
    "             \n",
    "             \"metrics_val\" should contain metrics (the metrics in params.metrics) computed\n",
    "             after each epoch on the validation set (metrics_train is similar). \n",
    "             You can use this to debug your models\n",
    "    \"\"\"\n",
    "    \n",
    "    val_metrics_epoch = []\n",
    "    train_metrics_epoch = []\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return {\n",
    "        \"metrics_val\": val_metrics_epoch,\n",
    "        \"metrics_train\": train_metrics_epoch\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "109d4be0105ee65f2e446c5d1a961eea",
     "grade": false,
     "grade_id": "cell-36910488e505a73a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# uncomment to test your code\n",
    "# listwise_params_test = Namespace(epochs=1, lr=1e-3, batch_size=1, metrics={\"ndcg\"})\n",
    "# listwise_net = NeuralModule(1)\n",
    "# train_listwise(listwise_net, listwise_params_test)\n",
    "# evaluate_model(listwise_net, \"test\", print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "275a63cf01f8efa9cb9b42b45d41aa9b",
     "grade": false,
     "grade_id": "cell-27de808a4c9d6bf6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The following cell saves your results in `listwise.json` file for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b50d890fdac41f183467a165cc71ae6",
     "grade": false,
     "grade_id": "cell-8c3dde9e1dcde277",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "seed(42)\n",
    "params = Namespace(epochs=8, \n",
    "                    lr=1e-4,\n",
    "                    batch_size=1,\n",
    "                    metrics={\"ndcg\", \"precision@05\", \"recall@05\"})\n",
    "listwise_model = NeuralModule(1)\n",
    "\n",
    "create_results(listwise_model, \n",
    "               train_listwise, \n",
    "               listwise_model,\n",
    "               \"./listwise.json\",\n",
    "               params)\n",
    "\n",
    "# persist model\n",
    "torch.save(listwise_model.state_dict(), \"./listwise_wt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cbccf7ada9159548390a5d8d28df92d1",
     "grade": true,
     "grade_id": "cell-6c37b60a428d000a",
     "locked": false,
     "points": 35,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e086691009a4dc0f8013c9f7f2d61bf",
     "grade": true,
     "grade_id": "cell-6c8d3b2e4ab668b1",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert os.path.exists(\"./listwise.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a1aaed7333acfcbdf24046a15cc5a2b",
     "grade": false,
     "grade_id": "cell-e47b21d69c9be1e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Section 6: Comparing Pointwise, Pairwise and Listwise (70 points) <a class=\"anchor\" id=\"evaluation1\"></a>\n",
    "\n",
    "[Back to TOC](#top)\n",
    "\n",
    "In the next few cells, we will compare the methods you've implemented. Helper functions are provided for you, which you can use to make some conclusions. You can modify the code as needed (you are encouraged to do so!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autolabel(ax, rects, labels):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for l, rect in zip(labels, rects):\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(l),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom',\n",
    "                   fontsize=7)\n",
    "\n",
    "def compare_methods(labels, metrics, metrics_to_plot={\"ndcg\", \"precision@05\", \"recall@05\"}):\n",
    "    \"\"\"\n",
    "    Constructs bar plots to compare different methods. \n",
    "    \n",
    "    labels: list/tuple of length N\n",
    "    metrics: list/tuple of length N, containing dictionary containing the test set results \n",
    "    metrics_to_plot: set of metrics to plot - each metric creates a separate plot \n",
    "    \"\"\"\n",
    "    assert len(metrics) == len(labels)\n",
    "    \n",
    "    x = np.arange(len(metrics_to_plot)) \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(metrics_to_plot), sharey=False)\n",
    "    fig.set_figheight(7)\n",
    "    fig.set_figwidth(15)\n",
    "    \n",
    "    colors = cm.get_cmap(\"Set1\").colors\n",
    "\n",
    "    for metric, ax, c in zip(metrics_to_plot, axes, colors):\n",
    "        m = [_[metric][0] for _ in metrics]  \n",
    "        std = [_[metric][1] for _ in metrics]\n",
    "        x = np.arange(len(labels))\n",
    "        rects = ax.bar(x, m, label=metric, color=c)\n",
    "        \n",
    "        l = [\"{0:.4f}({1:.4f})\".format(_[metric][0], _[metric][1]) for _ in metrics]\n",
    "        autolabel(ax, rects, l)\n",
    "        \n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(labels, rotation=45)\n",
    "        ax.set_yticks(np.linspace(0, 1, num=11))\n",
    "        ax.set_ylim(ymin=min(m) - 0.05, ymax= max(m) + 0.05)\n",
    "        ax.set_title(metric)\n",
    "    \n",
    "    \n",
    "\n",
    "def plot_distribution(labels, q_metrics, metric=\"ndcg\"):\n",
    "    \"\"\"\n",
    "    Plots the distribution of NDCG scores\n",
    "    \n",
    "    labels: list/tuple of length N\n",
    "    q_metrics: list/tuple of dictionaries with length N, containing the query level results\n",
    "    metric: the metric to plot\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n = len(labels)\n",
    "    # nC2\n",
    "    n_plots = int((n*(n-1))/2)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=n_plots, ncols=1)\n",
    "    fig.set_figheight(8 * n_plots)\n",
    "    fig.set_figwidth(10)\n",
    "    \n",
    "    colors = cm.get_cmap(\"Set1\").colors\n",
    "    \n",
    "    for idx, (i, j) in enumerate(itertools.combinations(range(n), 2)):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        im = q_metrics[i][metric]\n",
    "        jm = q_metrics[j][metric]\n",
    "        \n",
    "        ax.hist(im, bins=50, label=labels[i], color=colors[i], alpha=0.55)\n",
    "        ax.hist(jm, bins=50, label=labels[j], color=colors[j], alpha=0.55)\n",
    "        \n",
    "        ax.set_title(f\"{labels[i]} vs {labels[j]}\")\n",
    "        ax.legend()\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.set_xlabel(\"NDCG (binned)\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10071c1830b37c08ea6accb26accb372",
     "grade": false,
     "grade_id": "cell-b8d4e6f2d2e78550",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load metrics and models\n",
    "\n",
    "pointwise_regr_model = NeuralModule(1)\n",
    "pointwise_regr_model.load_state_dict(torch.load(\"./pointwise_regr_wt\"))\n",
    "\n",
    "pointwise_clf_model = NeuralModule(5)\n",
    "pointwise_clf_model.load_state_dict(torch.load(\"./pointwise_clf_wt\"))\n",
    "pointwise_clf_pred_fn = partial(clf_pred, net=pointwise_clf_model)\n",
    "\n",
    "pairwise_model = NeuralModule(1)\n",
    "pairwise_model.load_state_dict(torch.load(\"./pairwise_wt\"))\n",
    "\n",
    "listwise_model = NeuralModule(1)\n",
    "listwise_model.load_state_dict(torch.load(\"./listwise_wt\"))\n",
    "\n",
    "\n",
    "methods = [\n",
    "    {\"results_file\": \"./pointwise_regression.json\", \"label\": \"Pointwise (R)\"},\n",
    "    {\"results_file\": \"./pointwise_classification.json\", \"label\": \"Pointwise (C)\"},\n",
    "    {\"results_file\": \"./pairwise.json\", \"label\": \"Pairwise\"},\n",
    "    {\"results_file\": \"./listwise.json\", \"label\": \"Listwise\"}\n",
    "]\n",
    "\n",
    "labels = []\n",
    "results = []\n",
    "q_results = []\n",
    "for m in methods:\n",
    "    labels.append(m[\"label\"])\n",
    "    \n",
    "    with open(m[\"results_file\"]) as reader:\n",
    "        r = json.load(reader)\n",
    "    \n",
    "    results.append(r[\"test_metrics\"])\n",
    "    q_results.append(r[\"test_query_level_metrics\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62939c8a4fe146ee5833f48a92142e10",
     "grade": false,
     "grade_id": "cell-c4ac703bc5a62d3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "compare_methods(labels, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa461417560d69ebe07df21a8ad9b48e",
     "grade": false,
     "grade_id": "cell-a1ea52fda896045e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_distribution(labels, q_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c6e424fb4065a175111443cfbf26c618",
     "grade": false,
     "grade_id": "cell-d6d65f1ab73cda9a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the next cell, report the performance metrics for the methods (25 points):\n",
    "\n",
    "\n",
    "\n",
    "|     Model    | NDCG (s.d)| Precision@5 (s.d) | Recall@5 (s.d) |\n",
    "|:------------:|:----------:|:-----------:|:--------:|\n",
    "| Pointwise(R) |            |             |          |\n",
    "| Pointwise(C) |            |             |          |\n",
    "|   Pairwise   |            |             |          |\n",
    "|   Listwise   |            |             |          |\n",
    "\n",
    "\n",
    "\n",
    "**Rubric:** Each reported <Method, Metric> carries 2 points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89bf20199df56a7b90fa88c132800f23",
     "grade": true,
     "grade_id": "cell-5e733f8b8649a66f",
     "locked": false,
     "points": 25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "-> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c36dc224821c1146261aa2e8d06bd419",
     "grade": false,
     "grade_id": "cell-067c6d8584df601e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Write a conclusion in the next cell, considering (45 points):\n",
    "- rates of convergence\n",
    "- time complexity\n",
    "- performance wrt the 3 metrics\n",
    "- performance across queries\n",
    "- ... any other observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b8b4816351280cae45a1e498d1408fe",
     "grade": true,
     "grade_id": "cell-115db704e85b78c1",
     "locked": false,
     "points": 45,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b56e576a11e8312912751b345e72bfa",
     "grade": false,
     "grade_id": "cell-1693a9c859f14127",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Chapter 2: Online LTR (180 points) <a class=\"anchor\" id=\"onLTR\"></a>\n",
    "\n",
    "[Back to TOC](#top)\n",
    "\n",
    "In this part we want to use user interactions for training learning to rank algorithms.\n",
    "This part consists of the following sections:\n",
    " - Clicks Simulation (15 points)\n",
    " - Counterfactual Learning to Rank (80 points)\n",
    " - Online Evaluation (50 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "676f010e1d093ec248035d00c6888bf4",
     "grade": false,
     "grade_id": "cell-cb0180fd80d4f2cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Section 1: Clicks Simulation (15 points) <a class=\"anchor\" id=\"clicks\"></a>\n",
    "\n",
    "[Back to TOC](#top)\n",
    "\n",
    "In online LTR, we work with user interactions such as clicks.\n",
    "One way to test online LTR algorithms is to conduce semi-synthetic experiments.\n",
    "In semi-synthetic experiments, the feature vectors of a LTR dataset (similar to what you used in Part 1) are used.\n",
    "But instead of using the relevance labels for training the LTR algorithm, **simulated clicks** are used.\n",
    "\n",
    "In this section we want to simulate clicks based on the labels and use the generated clicks in later sections to train our Counterfactual LTR (CLTR) algorithm.\n",
    "\n",
    "First we need to have a *production ranker* that determines the order of documents for each query.\n",
    "The click probability of each document depends on its rank in the results list as well as its relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efe77df779addec15df70a2bd8a7aaee",
     "grade": false,
     "grade_id": "cell-4ae04e0717236f54",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ranks = dataset.load_production_ranker()\n",
    "print(f'ranks has {len(ranks.keys())} keys: {ranks.keys()}')\n",
    "for key in ranks:\n",
    "    print(f'{key} shape:{ranks[key].shape}')\n",
    "    \n",
    "data.train.ranks = ranks['train']\n",
    "data.validation.ranks = ranks['valid']\n",
    "data.test.ranks = ranks['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc0ae9b0654edea0e837893b613af5b8",
     "grade": false,
     "grade_id": "cell-86dfb91f27aeb1cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Implementation (5 points):**\n",
    "Now use the `ranks` to generate clicks.\n",
    "We assume documents with label $[3,4]$ are relevant and labels $[0,1,2]$ are non-relevant.\n",
    "We also assume the examination probability of a document at rank $r$ is $\\frac{1}{r}$.\n",
    "Finally, we assume a $0.05$ noise.\n",
    "\n",
    "This means that the click probability of a document with label $[3,4]$ at rank $r$ is $\\frac{1}{r}$, while the click probability of a document with label $[0,1,2]$ at rank $r$ is $\\frac{0.05}{r}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8bdfcf8895e430580912b057991ac7c0",
     "grade": false,
     "grade_id": "cell-6302b18566bcece2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (5 points)\n",
    "def generate_clicks(ranking, query_labels):\n",
    "    \"\"\"\n",
    "    Generates random clicks based on the given list of ranking and relevance labels for the documents of one query.\n",
    "    Input:\n",
    "        ranking: contains the rank of documents, eg. ranking[5]=0 means that document 5 is shown at rank 0.\n",
    "        query_labels: contains the labels of documents, eg. query_labels[5]=3 means that document 5 has a label equal to 3.\n",
    "    Output:\n",
    "        A np.array of clicked positions, eq. clicked=[1,4] meanse that documents at ranks 1 and 4 have been clicked. Note that document at rank 1 may differ from document 1 (see description of ranking input).\n",
    "        \n",
    "    Hint: Use the np.random.binomial function for generating click from probability.\n",
    "    \"\"\"\n",
    "    theta = 1. / np.arange(1, ranking.shape[0] + 1)\n",
    "    noise_prob = 0.05 * theta\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return clicked.astype(np.int32)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d5eeabc53fd3a13bb33d46f631ab3d5",
     "grade": true,
     "grade_id": "cell-098685a98a1887f4",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ranking = np.array([2, 1, 3, 0, 4, 7, 5, 6])\n",
    "labels = np.array([0, 3, 4, 1, 1, 2, 4, 3])\n",
    "\n",
    "np.random.seed(4)\n",
    "print(f'clicks: {generate_clicks(ranking, labels)}')\n",
    "print('expected clicks for seed 4: [0 1 6]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5fdf6ed2c6545213fb432e06dafb088e",
     "grade": false,
     "grade_id": "cell-a45b9902b9ff34c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Implementation (10 points):**\n",
    "Use `generate_clicks` to simulate clicks for different query sessions.\n",
    "For this, randomly select a query id, generate random clicks on documents of that query using your `generate_clicks` implementation and only keep the clicks on `topk` positions (i.e. do not consider clicks on ranks after `topk` rank).\n",
    "Repeat this process until you have `click_count` number of clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea8a1c5964a999322c4b30bdeecf88e6",
     "grade": false,
     "grade_id": "cell-cef4496878e0428a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (10 points)\n",
    "def simulate_clicks(data, split_name, click_count, topk=20):\n",
    "    \"\"\"\n",
    "    Simulate click_count clicks on topk results on the specified split of the data.\n",
    "    Output:\n",
    "        A list L=[L_0, L_1, ..., L_n] of lists. Each L_i is itself a list of clicks over the documents of query number i, eg. L_0=[0,2,0,1,0,5,2] means that in the sessions of the first query, the documents at positions 0,1,2 and 5 were clicked 3,1,2 and 1 times, respectively.\n",
    "    \"\"\"\n",
    "    data_split = getattr(data, split_name)\n",
    "#     argsorted, doclist_ranges = dataset.clean_and_sort(ranks, data_split, topk)\n",
    "\n",
    "#     click_data_split = Namespace(feature_matrix = data_split.feature_matrix[argsorted,:],\n",
    "#                                 doclist_ranges = doclist_ranges,\n",
    "#                                 clicks = None)\n",
    "#     labels = data_split.label_vector[argsorted]\n",
    "\n",
    "#     num_queries = click_data_split.doclist_ranges.shape[0] - 1\n",
    "    num_queries = data_split.doclist_ranges.shape[0] - 1\n",
    "    clicks = [[] for _ in range(num_queries)]\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "257a37637e4baec5b5da06cfb28f9c10",
     "grade": false,
     "grade_id": "cell-d31c106145d57d5a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use `simulate_clicks` function to simulate clicks for train and validation sets.\n",
    "\n",
    "**Note:**\n",
    "You can dump your generated clicks using pickle or numby and load them in your future runs to avoid long waiting times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe427c2102d2999e8bd2a6243c0d18b6",
     "grade": true,
     "grade_id": "cell-c7adb3055f3a3d5c",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_clicks = simulate_clicks(data,'train', click_count = 10000)\n",
    "\n",
    "assert isinstance(train_clicks, list)\n",
    "session_clicks = np.array(list(map(len, train_clicks)))\n",
    "print(f'{session_clicks.sum()} clicks simulated over {session_clicks.shape[0]} queries.')\n",
    "print(f'On average, each session has {session_clicks.mean()} clicks.')\n",
    "print(f'min number of clicks per session:{session_clicks.min()}')\n",
    "print(f'max number of clicks per session:{session_clicks.max()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87c03dbedf499cbb4ce724f2e97dc8aa",
     "grade": false,
     "grade_id": "cell-f6996aa4808d7747",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For our new click data, we need a new dataloader.\n",
    "`QueryGroupedOnlineLTRData` provides what you will need for training an LTR model from the clicks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da61ee98e6094a5bf41deff34136be4e",
     "grade": false,
     "grade_id": "cell-036f66cea8bae0bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class QueryGroupedOnlineLTRData(Dataset):\n",
    "    def __init__(self, data, split, clicks, topk):\n",
    "        self.split = {\n",
    "            \"train\": data.train,\n",
    "            \"validation\": data.validation,\n",
    "            \"test\": data.test\n",
    "        }.get(split)\n",
    "        assert self.split is not None, \"Invalid split!\"\n",
    "        self.clicks = clicks\n",
    "        self.topk = topk\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.split.num_queries()\n",
    "\n",
    "    def __getitem__(self, q_i):\n",
    "        s_i = self.split.doclist_ranges[q_i]\n",
    "        e_i = self.split.doclist_ranges[q_i + 1]\n",
    "        feature_ = self.split.feature_matrix[s_i:e_i,:]\n",
    "        ranking = self.split.ranks[s_i:e_i]\n",
    "        inverse_ranking = np.argsort(ranking)\n",
    "#       We re-order the rows of feature matrix so that in coincides with the ranking of documents.\n",
    "#       We also cut the documents after rank topk.\n",
    "        feature = torch.FloatTensor(feature_[inverse_ranking[:self.topk],:])\n",
    "        clicks = self.clicks[q_i]\n",
    "        return q_i, feature, clicks\n",
    "    \n",
    "def qgo_collate_fn(batch):\n",
    "    \n",
    "    qids = []\n",
    "    features = []\n",
    "    clicks = []\n",
    "    \n",
    "    for (q, f, l) in batch:\n",
    "        qids.append(q)\n",
    "        features.append(f)\n",
    "        clicks.append(l)\n",
    "    return qids, features, clicks\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "33284e30370a8dfdd116267499660b27",
     "grade": false,
     "grade_id": "cell-3ff364596e375e19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Section 2: Counterfactual LTR (90 points) <a class=\"anchor\" id=\"cLTR\"></a>\n",
    "\n",
    "[Back to TOC](#top)\n",
    "\n",
    "Now we want to use the simulated clicks and train a counterfactual LTR algorithm.\n",
    "We will use a simple loss function:\n",
    "\n",
    "$$\n",
    "L=\\frac{1}{|Q|} \\sum_{q \\in Q} \\sum_{d \\in D_q} r(d, q) \\cdot \\lambda(\\bar{rank}(d, D_q))\n",
    "$$\n",
    "where $Q$ is the set of queries, $D_q$ is the list of documents shown to the user for query $q$, $r(d, q)$ is the relevance of document $d$ to query $q$ and $rank(d, D_q)$ is the rank of $d$ in $D_q$.\n",
    "\n",
    "In this assignment, we use sigmoid-like bound for $\\lambda(\\bar{rank}(d, D_q))$:\n",
    "\n",
    "$$\n",
    "\\lambda(\\bar{rank}(d, D_q)) = \\sum_{d' \\in D_q} log\\left(\n",
    "1+exp\\left(-2\\cdot(f(d)-f(d')\\right)\n",
    "\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a52232af5a6b442146258942ced99353",
     "grade": false,
     "grade_id": "cell-5d364d940f11536e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Section 2.1. Biased LTR (20 points)\n",
    "\n",
    "Remember that we do not have the explicit relevance in the online settings.\n",
    "Instead, we have to learn from the clicks.\n",
    "Clicks, implicitly indicate relevance.\n",
    "A naive approach for learning from clicks would be to replace relevance with clicks and train a model with the loss function:\n",
    "\n",
    "$$\n",
    "L_{biased}=\\frac{1}{|Q|} \\sum_{q \\in Q} \\sum_{d \\in D_q} c(d, q) \\cdot \\lambda(\\bar{rank}(d, D_q))\n",
    "$$\n",
    "where $c(d, q)$ indicates the number of times $d$ was clicked for query $q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "defc1880152e68dd36c21992263f8d56",
     "grade": false,
     "grade_id": "cell-6b45762861989c96",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (20 points)\n",
    "def online_loss_biased(scores, clicks):\n",
    "    \"\"\"\n",
    "    Compute and return the biased online loss *for a single query*. To compute this, use L_{biased} formula above.\n",
    "    \n",
    "    scores: tensor of size [N, 1] (the output of a neural network), where N = length of <query, document> pairs\n",
    "    clicks: list of clicked ranks. \n",
    "    \n",
    "    Note: the scores are aligned with the click positions, i.e. scores[0] corresponds to the 0 rand, etc.\n",
    "    \n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    click_counts = Counter(clicks)\n",
    "    \n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd1acc24a7415fcae69fa183a51afb28",
     "grade": true,
     "grade_id": "cell-d09e7eb339052376",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "scores = torch.FloatTensor([1.2, -2, 1.1, 2.4, 0, 1.2])[:,None]\n",
    "clicks = [0, 0, 1, 3, 1, 4, 0, 5, 0, 1, 2]\n",
    "print(f'biased loss: {online_loss_biased(scores, clicks)}')\n",
    "print(f'expected: -6.205410003662109')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "48efe214b4ffd699be8ebbbf0016b467",
     "grade": false,
     "grade_id": "cell-318d7a3b824c5f99",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Section 2.2. Unbiased LTR (10 points)\n",
    "Now modify `online_loss_biased` to debias the clicks, using IPS method:\n",
    "\n",
    "$$\n",
    "L_{unbiased}=\\frac{1}{|Q|} \\sum_{q \\in Q} \\sum_{d \\in D_q} \\frac{c(d, q)}{P\\left(o(d,q)=1\\right)} \\cdot \\lambda(\\bar{rank}(d, D_q))\n",
    "$$\n",
    "where $P\\left(o(d,q)=1\\right)$ indicates the probability that $d$ was observed by the user for query $q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e0238d2d1cabe1a3d21b0cc44a54d61",
     "grade": false,
     "grade_id": "cell-9362e909abcb1d91",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (10 points)\n",
    "def online_loss_unbiased(scores, clicks):\n",
    "    \"\"\"\n",
    "    Compute and return the unbiased online loss *for a single query*. To compute this, use L_{unbiased} formula above.\n",
    "    \n",
    "    scores: tensor of size [N, 1] (the output of a neural network), where N = length of <query, document> pairs\n",
    "    clicks: list of clicked ranks. \n",
    "    \n",
    "    Note 1: the scores are aligned with the click positions, i.e. scores[0] corresponds to the 0 rand, etc.\n",
    "    Note 2: the weights are provided.\n",
    "    \n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    click_counts = Counter(clicks)\n",
    "    weights = torch.Tensor((1./np.arange(1,scores.shape[0]+1))[:,None])\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2bcac0a6c4afe70fca335c8d648122f",
     "grade": true,
     "grade_id": "cell-30b468279fbb6de5",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "scores = torch.FloatTensor([1.2, -2, 1.1, 2.4, 0, 1.2])[:,None]\n",
    "clicks = [0, 0, 1, 3, 1, 4, 0, 5, 0, 1, 2]\n",
    "print(f'biased loss: {online_loss_unbiased(scores, clicks)}')\n",
    "print(f'expected: -17.11062240600586')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4f49c8953f6080ec340ebe076f9caf6",
     "grade": false,
     "grade_id": "cell-e385419532bb6535",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Implementation (60 points):**\n",
    "In the next cell, write a wrapper that uses your loss functions and simulated clicks to train an online LTR method (no evaluation on validation set is required):\n",
    "\n",
    "**Rubric:**\n",
    " - Network is trained for specified epochs, and iterates over the entire dataset and (train) data is shuffled : 10 points\n",
    " - Loss calculation: 10 points\n",
    " - Training (e.g optimizer, zero_grad, backward): 10 points\n",
    " - Performance as expected for biased loss: 15 points\n",
    " - Performance as expected for unbiased loss: 15 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1113e39b6c82d64e959436f049df22ac",
     "grade": false,
     "grade_id": "cell-155a60a13f0dabb3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (60 points)\n",
    "def train_online(net, train_clicks, loss_fn, params):\n",
    "    \"\"\"\n",
    "    Use QueryGroupedOnlineLTRData to load the data train split and clicks.\n",
    "    Use the appropriate loss_fn (biased/unbiased).\n",
    "    No need to use validation set.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "688a802dd604c3f002a9c5b26822b42d",
     "grade": false,
     "grade_id": "cell-2899cebacae54c00",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "params = Namespace(epochs=3, lr=1e-3, topk=20)\n",
    "train_clicks = simulate_clicks(data,'train', click_count = 50000)\n",
    "biased_net = NeuralModule(1)\n",
    "train_online(biased_net, train_clicks, online_loss_biased, params)\n",
    "unbiased_net = NeuralModule(1)\n",
    "train_online(unbiased_net, train_clicks, online_loss_unbiased, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ff8105a6912656bef1bf2642a977fee",
     "grade": false,
     "grade_id": "cell-0511eb2be587f032",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "evaluate_model(biased_net, 'test', print_results=True)\n",
    "evaluate_model(unbiased_net, 'test', print_results=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a5138ee2bdc3b5682d5ed8b7bcc1202",
     "grade": false,
     "grade_id": "cell-c497608f3d46e769",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "seed(42)\n",
    "train_clicks = simulate_clicks(data,'train', click_count = 50000)\n",
    "params = Namespace(epochs=3, \n",
    "                    lr=1e-3,\n",
    "                    batch_size=1,\n",
    "                    topk=20,\n",
    "                    metrics={\"ndcg\", \"precision@05\", \"recall@05\"})\n",
    "biased_model = NeuralModule(1)\n",
    "\n",
    "create_results(biased_model, \n",
    "               train_online, \n",
    "               biased_model,\n",
    "               \"./biased_model.json\",\n",
    "               train_clicks,\n",
    "               online_loss_biased,\n",
    "               params)\n",
    "# persist model\n",
    "torch.save(biased_model.state_dict(), \"./biased_wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9b104b0cc6204f1f3c6ac9bbf88171f",
     "grade": false,
     "grade_id": "cell-9df7065c5b887449",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "seed(42)\n",
    "\n",
    "params = Namespace(epochs=3, \n",
    "                    lr=1e-3,\n",
    "                    batch_size=1,\n",
    "                    topk=20,\n",
    "                    metrics={\"ndcg\", \"precision@05\", \"recall@05\"})\n",
    "unbiased_model = NeuralModule(1)\n",
    "\n",
    "create_results(unbiased_model, \n",
    "               train_online, \n",
    "               unbiased_model,\n",
    "               \"./unbiased_model.json\",\n",
    "               train_clicks,\n",
    "               online_loss_unbiased,\n",
    "               params)\n",
    "# persist model\n",
    "torch.save(biased_model.state_dict(), \"./unbiased_wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93ede3bc5a61edfb93777647c3ae0b1a",
     "grade": true,
     "grade_id": "cell-5a98cb1d4dccab54",
     "locked": false,
     "points": 30,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34fad8b3eebaaca7a38cf37fb55433e3",
     "grade": true,
     "grade_id": "cell-6eaff35ed2f350ea",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8cc768ddc4dd12732fc4c1b42cf015d",
     "grade": true,
     "grade_id": "cell-6a1e7d45a6b24c7c",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca775c32f1df7ef6d70c60b3e365adf4",
     "grade": false,
     "grade_id": "cell-08980b08558f70e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Section 2.3: Comparison (20 points)\n",
    "\n",
    "Now we can compare two loss functions: biased and unbiased.\n",
    "We want to see how they can improve by increasing the number of training clicks.\n",
    "Train both biased and unbaised models on $[2000, 10000, 50000]$ number of clicks and compare the results.\n",
    "\n",
    "Plot the results in a **single** figure with x-axis showing the number of trainin clicks and y-axis showing the nDCG@10.\n",
    "Discuss your observations.\n",
    "\n",
    "\n",
    "**Rubric:**\n",
    "- Two curves are plotted in the figure: 10 points\n",
    "- Clear titles, x label, y labels and legends (if applicable): 5 points\n",
    "- Explain what you observe: 5 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76693360dd6493e5811d1908eacf8227",
     "grade": true,
     "grade_id": "cell-f51a0be2734c9352",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce47393cb34036b50fde6780cdb9f772",
     "grade": false,
     "grade_id": "cell-6bd0ff7cecc1b060",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Section 3: Online Evaluation (75 points) <a class=\"anchor\" id=\"on_eval\"></a>\n",
    "\n",
    "[Back to TOC](#top)\n",
    "\n",
    "Sometimes, in online search engines, we want to compare two or more different ranking functions based on the user interactions.\n",
    "This comparison is done via online evaluation.\n",
    "\n",
    "In this section we implement one of the online evaluation methods: probabilistic multileaving.\n",
    "\n",
    "We compare three rankers:\n",
    " - Production ranker: the ranks that are provided to you for doing the click simulation.\n",
    " - Biased method from previous section.\n",
    " - Unbiased method from previous section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "590bdae1272cdd45e304d0498de730bc",
     "grade": false,
     "grade_id": "cell-6ca9cf6f08e6b7f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Before proceeding, we need some auxiliary functions:\n",
    "\n",
    " - `invert_ranking` gets the ranking and gives the inverted rankings. This means that for an input with `rank[d]=r`, the output would be `i_rank[r]=d`.\n",
    "\n",
    "\n",
    " - `get_predictions` gives a dictionary of predictions, i.e. `predictions[qid]` is the list of scores produced by the given model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98f77357b3d3088c738c97a90bd05061",
     "grade": false,
     "grade_id": "cell-3ae14fda3426a247",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_predictions(net, test_clicks, topk):\n",
    "    test_dl = DataLoader(QueryGroupedOnlineLTRData(data, 'test', test_clicks, topk), \n",
    "                          batch_size=1, \n",
    "                          shuffle=False,\n",
    "                          collate_fn=qg_collate_fn)\n",
    "    predictions = {}\n",
    "    for qids, x, _ in test_dl:\n",
    "        predictions[qids[0]] = net(x[0]).detach().numpy()[:,0]\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def invert_rankings(rankings):\n",
    "    '''\n",
    "    Invert indices in a matrix of rankings, ranking per row.\n",
    "    '''\n",
    "    inverted = np.zeros(rankings.shape)\n",
    "    \n",
    "    inverted[np.arange(rankings.shape[0])[:,None],rankings] = np.arange(rankings.shape[1])[None,:]\n",
    "    return inverted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "715b799e36aa757ed9db3dd60c9b724e",
     "grade": false,
     "grade_id": "cell-7bbf6c13e9eaea91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The next cell helps you build the ranking matrix for each query in the test set.\n",
    "The first row is the production ranker, the second row is the biased ranker and the third row is the unbiased ranker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f2a6904a62575980830a95ed5ee238d",
     "grade": false,
     "grade_id": "cell-3bdf5ac68c468d35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# we only need the ranking of the production ranker for the test set. No clicks have to be simulated here.\n",
    "test_clicks = simulate_clicks(data, 'test', click_count = 0)\n",
    "biased_predictions = get_predictions(biased_net, test_clicks, 20)\n",
    "unbiased_prediction = get_predictions(unbiased_net, test_clicks, 20)\n",
    "\n",
    "def get_ranking_matrix(qid, topk):\n",
    "    ranking_matrix = np.empty([3, min(data.test.query_size(qid), topk)], dtype=np.int32)\n",
    "    ranking = data.test.ranks[data.test.doclist_ranges[qid]:data.test.doclist_ranges[qid+1]]\n",
    "    ranking_matrix[0,:] = np.arange(ranking_matrix.shape[1])\n",
    "    ranking_matrix[1,:] = np.argsort(-biased_predictions[qid])\n",
    "    ranking_matrix[2,:] = np.argsort(-unbiased_prediction[qid])\n",
    "    return ranking_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5cc0c513947abfc38bd19f364c24992",
     "grade": false,
     "grade_id": "cell-77d4e88031772611",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(get_ranking_matrix(0, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3a1de51e80c9251462e68fb16b4fb0f",
     "grade": false,
     "grade_id": "cell-ff251675418a5a1a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Section 3.1 Multileaving (10 points)\n",
    "\n",
    "Given the rankings of multiple rankers, we want to decide how to fill the results list and show it to the users.\n",
    "Implement the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1f9c735274c6a469bd089afd078bcf9",
     "grade": false,
     "grade_id": "cell-fcf5351ca3d36caa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (10 points)\n",
    "def make_multileaving(inverted_rankings, topk):\n",
    "    '''\n",
    "    ARGS: (all np.array of docids)\n",
    "    - inverted_rankings: matrix (rankers x documents) where [x,y] corresponds to the rank of doc y in ranker x\n",
    "    RETURNS\n",
    "    - ranking of indices corresponding to inverted_rankings\n",
    "    '''\n",
    "    n_rankers = inverted_rankings.shape[0]\n",
    "    n = inverted_rankings.shape[1]\n",
    "    k = min(n, topk)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(make_multileaving(invert_rankings(get_ranking_matrix(0, 20)), 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51819e8bd101b87700217e0ea4983c40",
     "grade": true,
     "grade_id": "cell-a7f83f82f0a41b58",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ca3e1ec97c81db9c4a9e3d7ec81919c",
     "grade": false,
     "grade_id": "cell-024ab191ba5fc1c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Section 3.2: Probability of rankers (15 points)\n",
    "\n",
    "We have shown the multileaved list to the user and they clicked on some documents.\n",
    "In this function we want to calculate the probability that the clicked documents belong to a specific ranker.\n",
    "\n",
    "Note that the results of rankers are not unique and each document in the results list may belong to different rankers.\n",
    "So we need to assign a *probability* to each click belonging to each ranker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6150d058189bef659154cdb1e700d18",
     "grade": false,
     "grade_id": "cell-06a948902936dd40",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (15 points)\n",
    "def probability_of_list(result_list, inverted_rankings, clicked_docs):\n",
    "    '''\n",
    "    ARGS: (all np.array of docids)\n",
    "    - result_list: the multileaved list\n",
    "    - inverted_rankings: matrix (rankers x documents) where [x,y] corresponds to the rank of doc y in ranker x\n",
    "    - clicked_docs: boolean array of result_list length indicating clicks\n",
    "    RETURNS\n",
    "    -sigmas: matrix (rankers x clicked_docs) with probabilty ranker added clicked doc\n",
    "    '''\n",
    "    n_docs = inverted_rankings.shape[1]\n",
    "    n_rankers = inverted_rankings.shape[0]\n",
    "\n",
    "    click_doc_ind = result_list[clicked_docs]\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "216c6987df2ad52d86dec05976823892",
     "grade": false,
     "grade_id": "cell-cb41d992a09ed02e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ranking_matrix = get_ranking_matrix(0, 20)\n",
    "result_list = make_multileaving(invert_rankings(ranking_matrix), 20)\n",
    "clicks = [0,4,9,10]\n",
    "probabilities = probability_of_list(result_list, invert_rankings(ranking_matrix), clicks)\n",
    "print(f'ranking matrix:\\n {ranking_matrix}')\n",
    "print(f'results list (shown to user):\\n {result_list}')\n",
    "print(f'clicked documents: {clicks}')\n",
    "print(f'probabilities:\\n {probabilities}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b4921314264ee89e72d616cf8ee8f33",
     "grade": true,
     "grade_id": "cell-41eadc2f4faaf437",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7cdd78a87da0a5d3a05207c5e926eef4",
     "grade": false,
     "grade_id": "cell-95c4e4ae05ce7198",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Section 3.3: Preference matrix (10 points)\n",
    "\n",
    "Given the probabilities of each ranker being clicked, we want to calculate a preference matrix that for each pair of rankers tells us which one is preferred by the clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec8f2075b4b94720bdf96898d4254589",
     "grade": false,
     "grade_id": "cell-931bf5baba8e9eac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (10 points)\n",
    "def preferences_of_list(probs):\n",
    "    '''\n",
    "    ARGS:\n",
    "    -probs: clicked docs x rankers matrix with probabilities ranker added clicked doc  (use probability_of_list)\n",
    "    -n_samples: number of samples to base preference matrix on\n",
    "    RETURNS:\n",
    "    - preference matrix: matrix (rankers x rankers) in this matrix [x,y] > 0 means x won over y and [x,y] < 0 means x lost from y\n",
    "      the value is analogous to the (average) degree of preference\n",
    "    '''\n",
    "    n_samples = 10\n",
    "    n_clicks = probs.shape[0]\n",
    "    n_rankers = probs.shape[1]\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def infer_preferences(inverted_rankings, result_list, clicked_docs):\n",
    "    n_rankers = inverted_rankings.shape[0]\n",
    "    if np.any(clicked_docs):\n",
    "        return preferences_of_list(probability_of_list(result_list,\n",
    "                                        inverted_rankings,\n",
    "                                        clicked_docs))\n",
    "    else:\n",
    "        return np.zeros((n_rankers, n_rankers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2342811f833dbdbc29a5f7f5725b576",
     "grade": false,
     "grade_id": "cell-9598544608fbcde8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(preferences_of_list(probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e79d7a1992af19a5fcd6711ece693800",
     "grade": true,
     "grade_id": "cell-601defbd1e14a840",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0360fb3c0a060e97efd327ec0cc79468",
     "grade": false,
     "grade_id": "cell-766b24e1ede46a8c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we can simulate the multileaving to see how our target rankers are evaluated by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d071088604059a588482912e2a0dfd2",
     "grade": false,
     "grade_id": "cell-45aaaa7c7a055fed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def simulate_multileaving(n_impressions, topk):\n",
    "    n_samples = 10\n",
    "    impressions = 0\n",
    "    pref_update = 0\n",
    "    total_pref = np.zeros((3, 3))\n",
    "    for step_i in range(n_impressions):\n",
    "        qid = np.random.randint(0, data.test.doclist_ranges.shape[0] - 1)\n",
    "\n",
    "        start_i = data.test.doclist_ranges[qid]\n",
    "        end_i = data.test.doclist_ranges[qid + 1]\n",
    "        n_query_docs = end_i - start_i\n",
    "        query_labels = data.test.label_vector[start_i:end_i]\n",
    "\n",
    "        inverted_rankings = invert_rankings(get_ranking_matrix(qid, topk))\n",
    "        multileaving = make_multileaving(inverted_rankings, topk)\n",
    "\n",
    "        cur_clicks = generate_clicks(multileaving, query_labels)\n",
    "\n",
    "        if np.any(cur_clicks):\n",
    "            pref = infer_preferences(inverted_rankings, multileaving, cur_clicks)\n",
    "            total_pref += pref\n",
    "            pref_update += 1\n",
    "    return total_pref / pref_update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95b61f7faa7cb7febe3d00fb66d0cda3",
     "grade": false,
     "grade_id": "cell-eae8a938c37a37f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "simulate_multileaving(10000, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29bb96f857fa7ae1dc2d816a1b888d7b",
     "grade": false,
     "grade_id": "cell-04ee05c85dd0304d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Section 3.4: Analysis (40 points)\n",
    "\n",
    "Analyze the behavior of your multileaving implementation by testing it with two different `topk` values: $[5,20]$ and with different number of evaluation clicks: $[2000, 10000, 50000]$.\n",
    "\n",
    "Put the preference of the unbiased method over the biased method (i.e. `pref[2,1]` in the matrix output of `simulate_multileaving` function) for these experiments in a table.\n",
    "\n",
    "**Rubric:**\n",
    "- Six experiments: 12 points\n",
    "- Analysis of the observations: 28 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd41d14078b1ad160c02cf690c45e55f",
     "grade": true,
     "grade_id": "cell-d88f4eb3035e6fbb",
     "locked": false,
     "points": 40,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "280px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
